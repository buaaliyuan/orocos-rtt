<?xml version='1.0'?>

<!DOCTYPE book PUBLIC "-//OASIS//DTD DocBook XML V4.1.2//EN"
"/usr/share/sgml/docbook/dtd/xml/4.1.2/docbookx.dtd"
[
<!ENTITY orocos      "<acronym>Orocos</acronym>">
]
>

<book>
  <bookinfo>
  <title>Controlling a web served six degrees of freedom industrial robot</title>
  <authorgroup>
    <collab>
      <collabname>Peter Soetens, K.U.Leuven, Belgium</collabname>
    </collab>
  </authorgroup>
  <copyright>
   <year>2002</year>
   <holder>Peter.Soetens@mech.kuleuven.ac.be</holder>
  </copyright>
  </bookinfo>

  <chapter>
    <title>Introduction</title>
    <para>
    The task is to control a fixed six degrees of freedom industrial robot arm
    in hard realtime.
    It is equipped with a 6D ( XYZ forces and torques ) force sensor at its end 
    effector, designed for detecting contact with surfaces. Objects will be 
    placed nearby the robot and it should be able to deduce the shape by touching 
    it with its 'finger'.

    The owner of the robot wants to control it with common hardware components and 
    dedicated acquisition cards. The cost of the software should be kept at a 
    minimum. The development platform must allow easy integration with existing 
    software technologies, which then don't have to be developed in house but 
    can be reused instead.

    Further, the control computer should easily be accessed over the Internet
    to give online demonstrations with a web cam.
    </para>
<informalfigure>
<mediaobject>
<imageobject>
<imagedata fileref="setup.png" srccredit="PS,2002"/>
</imageobject>
<!--
<textobject><phrase>Wat Arun</phrase></textobject>
<caption><para>Wat Arun, Temple of the Dawn, on the Chao Phraya River
in Bangkok,
Thailand. In April, 1998, Wat Arun was in the midst of renovation.</para>
</caption>
-->
</mediaobject>
</informalfigure>
    <para>
        Three aspects of a software control system have to be studied: 
        hardware configuration, operating system and application design. 
    </para>
    <sect1>
    <title>Hardware</title>
    <para>
        The Intel X86 architecture is a favourite candidate
        since a lot of acquisition cards are available for this 
        architecture and all components
        are very easily and cheaply obtained. The components of such a 
        system are called Common Off The Shelf (COTS) hardware.
        The hardware is extended by means of the USB (Universal
        Serial Bus) ports,the PCI (Peripheral Component Interface) bus, 
        and the classic parallel and serial ports.
        The choice of hardware will be motivated in chapter 2.
    </para>
    </sect1>
    <sect1>
    <title>Software</title>
    <sect2>
    <title>The Realtime Operating System (RTOS)</title>
    <para>
        Hardware is addressed through a Hardware Abstraction Layer (HAL) 
        provided by the Operating Systems kernel and systems library.
        RealTime Linux, RTAI (the RealTime Abstraction Interface) and
        to a lesser extent eCos (embedded Configurable operating system)
        will be investigated. Other Free initiatives exist too, but have
        a smaller user base. RTAI and RTLinux are extensions of the Linux
        kernel and are, as a consequence, written in C.  eCos is written entirely
        in C++. 
</para>

<para>
        A major difference between eCos and the RTLinux / RTAI approach
        is that the latter also allow normal 'user' processes
        (like the web server) to run
        when no realtime tasks are running. A similar effect can be
        obtained by running the user task in eCos as the lowest
        priority process. The differences between these three will be
        pointed out in chapter 3.
</para>

<para>
        It's the task of the RTOS to encapsulate memory allocation,
        Inter Process Communication (IPC) and hardware access.
    </para>
    </sect2>
    <sect2>
    <title>The Object Oriented Programming paradigm</title>
    <para>
        Managing the complexity of any application has always been the
        greatest challenge for software designers. Due to inertia,
        lots of software is still written in procedural languages like
        C. The Object Oriented Programming (OOP) paradigm tries to
        provide a solution to control certain complexities that arise
        when programming. The most common aspects are data encapsulation
        by protected access, polymorphism and error handling by exceptions
        instead of return values. Correct use of polymorphism was 
        introduced by Liskov [ <xref linkend="Lisk88"></xref> ] and was a milestone in OOP. Another
        milestone was reached when
        "The Gang of Four" published "Software patterns for object
        oriented programming" [ <xref linkend="Gang94"></xref> ], and provided common terminology and
        solutions to well known programming problems.
</para>

<para>
        Object oriented languages like Java, Python and C++ have proven
        themselves to build very complex applications ranging from
        graphical desktop environments over distributed applications
        to operating systems itself, like eCos.
</para>

<para>
        Realtime systems complexity tend to grow fast because of timing
        constraints on data manipulation, complex 
        signal/event propagation through the system and data integrity.
        Not all object oriented facilities will be allowed for use
        in a realtime system, but many of the remaining will 
        ease implementation significantly. 
        </para>
        
        <para>
        Variants of object oriented programming languages like
        Embedded C++ [<ulink url="http://www.caravan.net/ec2plus/"></ulink>] 
        or realtime Java 
        [<ulink url="http://www.rtj.org"></ulink>] try to define a subset
        of the corresponding language facilities suitable for 
        realtime applications.
    </para>
    </sect2>
<!--   <sect2>
    <title>The Orocos Core</title>
    <para>
        The Orocos core tries to provide an object oriented library 
        for operating system access and a central subsystem for 
        synchronisation and Event handling. The details of the
        core subsystem are detailed in other papers. This paper
        will discuss the very foundations of the core subsystem
        and try to defend the decisions taken.
    </para>
    </sect2>
-->
    </sect1>
    </chapter>
    <chapter>
    <title>Hardware for realtime systems</title>
    <sect1>
    <title>The hardware configuration</title>
    <sect2>
    <title>Processors</title>
    <para>
        The application demands a general purpose processor capable of
        floating point calculations for performing
        the control loop and capable of protecting memory access for 
        user applications (web server). General purpose processors are mostly 
        CISCs (Complex Instruction Set Computer) because of the need
        of many instructions. With more and complexer instructions that the
        processor has to support, decoding of instructions becomes complexer
        too. Long instruction pipelines are commonly found on CISCs to
        fasten the fetch-decode-execute-store cycle.
        Intel is the main manufacturer of CISC general purpose processors.
    </para>
    <para>    
        The most common processors currently sold by Intel 
        are CISCs of the Pentium III and 
        Pentium IV series. A compatible processor is also produced by
        AMD (Advanced Micro Devices). 
        These processors have a 32 bit address space, allowing 4 GB of 
        addressable memory and have
        32 bit wide registers. They have a floating point unit, Level 1
        and Level 2 cache and a Memory Management Unit (MMU).
        
        Because of the heavy workload on
        the target configuration, we decide to use a SMP (Symmetric 
        Multi Processor ) system consisting of 2 processors. A dual processor
        system allows one processor to perform the hard realtime tasks and
        another doing the soft realtime or non deterministic executions.
        Two 700MHz Pentium III processors with 16KB Level 1 and 256KB Level 2 
        cache should be sufficient.
        
        The choice between the AMD processor or the Intel processor
        will be determined by the availability of motherboards.
    </para>
    <sect3>
    <title>Splitting workload over two processors</title>
    <para>
        Concrete for our application, all hard realtime tasks will run on one
        processor. These tasks are the control task and measurement task.
        All other tasks, being the command task and the web server, will
        run on the other processor. Chapter 4 will discuss the task distribution
        over processors profoundly.
    </para>
    </sect3>
    </sect2>
    <sect2>
    <title>Motherboard</title>
    <para>
        Each processor must be mounted on a motherboard to allow communication
        with the main memory and peripherals.
        There are a lot of SMP motherboards on the market for Intel processors
        and only a few for AMD. We need a motherboard with many PCI 
        slots for all the hardware cards. A local hardware reseller could
        provide us with the <ulink url="http://www.tri-m.com/products/icp/rockyp258bx_p228bx.html">ROCKY - P228BX Dual Pentium III Processor motherboard</ulink> in 
        combination with a <ulink url="http://www.arisecomputer.com/bp/px20s2.asp">PX-20S2 ISA/PCI Bridge Backplane </ulink>for use in a
        3U rack mountable case. 
        
        The motherboard provides two sockets for the processors, a watchdog
        timer, a parallel and serial port, a USB port and keyboard/mouse
        connectors. The chipset is the Intel 440BX chipset. The motherboard
        provides an IDE controller for up to four hard disks. The front side bus
        is clocked at 100 MHz.
        The backplane provides 17 PCI device slots.
    </para>
    </sect2>
    <sect2>
    <title>Non Volatile Storage</title>
    <para>
        Since the computer has to provide a web server and must allow to develop
        the software on the same machine, a hard disk drive is needed to store
        all non volatile data. An Adaptec Ultra 160 SCSI Controller and an
        IBM SCSI Hard disk of 20GB are added to the configuration to satisfy this
        need. An IDE CDROM is attached to the IDE controller, a floppy disk 
        drive to the floppy controller.
        The control application will only require a few megabytes of disk space
        to be stored on, so a Flash memory solution might be used
        if the system would ever be used only for control. The motherboard 
        provides a socket for Flash disks if needed.
    </para>
    </sect2>
    <sect2>
    <title>Volatile Storage</title>
    <para>
        The motherboards chipset specifies that the Random Access Memory (RAM) must be of
        the SDRAM (Synchronous-Dynamic RAM) type.  This is a very fast
        and cheap memory type. Address and data words are
        synchronously passed to an asynchronous DRAM array through registers
        present in the SDRAM chip. 
<!--        
        This is because SDRAM has an internal clocking mechanism 
        to refresh the DRAM array.
        All read and write requests pass through this timing generator and
        the addresses are written to an address register while data is
        read and written to a data register.
        
        Further, the memory read access is 
        pipelined, meaning that the critical path (microprocessor to memory back
        to microprocessor) is split into two stages.
        The first stage contains the control register over timing generator and
        DRAM array to a data read register. The second stage
        is from data read register over databus to micro processor.
-->        
        SDRAM consumes only little power since only the refresh cycle, which
        refreshes capacities representing the bits, consumes power for storage.
        
        A Dual In-line Memory Module (DIMM) of 256MB is chosen. It must be 
        compatible with the 100MHz system bus, so the SDRAM chips 
        frequency is 100MHz. The full size of the memory
        will not be needed during normal operation but allows development
        of the software on the same platform. An estimate of memory 
        requirements for normal operation is 8MB for the realtime part and
        8MB for a small web server.
    </para>
    </sect2>
    <sect2>
    <title>Data Acquisition and Output Cards</title>
    <para>
        The robot can be controlled through the following interface : 
        <itemizedlist>
        <listitem> 6 Analog inputs for joint velocity set points between
            -10V and +10V
        </listitem>
        <listitem> 6 position readings delivered through an SSI (
            Serial Synchronous Interface) protocol. The SSI protocol allows
            to 'pull' the position of three absolute position encoders
            at a time.
        </listitem>
        <listitem> 6 Digital inputs for holding or releasing the brakes
        </listitem>
        <listitem> 6 Digital inputs for enabling the motor amplifiers
        </listitem>
        <listitem> 12 Digital outputs for 12 end limit switches. Each joint
            has two switches indicating the two outer positions the joint
            can reach.
        </listitem>
        <listitem> 3 Digital outputs to feedback the internal status, meaning
            emergency stop, manual control enabled and a fault flag.
        </listitem>
        </itemizedlist>
        The force sensor has its own closed controller to gather the force
        readings and exports them through 6 analog outputs. Calibration
        must be done by the user.
    </para>
    <para>
        As can be seen, a lot of data has to be monitored or sent to the
        robot. AddiData <ulink url="http://www.addi-data.de/"></ulink>
        and National Instruments <ulink url="http://www.ni.com/"></ulink>
        are well known manufacturers
        of PCI cards for realtime data acquisition. The following cards were
        chosen :
        <itemizedlist>
        <listitem> Addidata APCI 1710 for reading the encoder positions
        </listitem>
        <listitem> Addidata APCI 2200 32 bits digital output card for
            controlling the brakes and the motor amplifiers
        </listitem>
        <listitem> Addidata APCI 1032 32 bits digital input card for
            reading the endlimit switches and status information
        </listitem>
        <listitem> National Instruments PCI 6013 with 16 analog inputs
            for reading the force sensor. The Digital/Analog (DA)
            converter is a fast 12 bits converter.
        </listitem>
        <listitem> National Instruments PCI 6713 with 8 analog outputs
            for the joint velocity setpoints having a fast 12 bits AD conversion.
        </listitem>
        </itemizedlist>
    </para>
    <para>
        Finally, a PCI graphics card is added for user interfacing and a
        100Mbit Ethernet card for network access.
    </para>
    </sect2>
    <sect2>
    <title>Web cam</title>
    <para>
        A small USB web cam will be connected to the USB port and pointed
        towards the robot.
    </para>
    </sect2>
    <sect2>
    <title>Conclusion</title>
    <para>
        These setups are hardly embedded but are cheap compared to dedicated
        hardware, with the same specifications and application. We have
        a web server, a development platform and a realtime controller in
        one machine. The choice of motherboard, processor and PCI cards
        imposes some limitations for realtime use.
        The next section will discuss some components 
        of the hardware architecture of the chosen system and implications
        for realtime use.
    </para>
        <!--
        <para>
        A well known processor in the embedded systems field is the Power PC, which
        is an example of a RISC (Reduced Instruction Set Computer) processor.
        Boards using Power PC processors
        usually communicate with the deterministic CAN bus system, use FLASH
        memory to store the program code and a few megabytes of SDRAM for 
        data access. The wide variety of marks and types allow highly customisable
        systems with a lot of hardware fit into one processor package, such as
        the CAN bus, Digital Analog conversion and interrupt timers.
        </para>
        <para>
        Not all types have a floating point unit on board, which might be
        important for software design.
    </para>
        -->
    </sect2>
    </sect1>
    <sect1>
    <title>The X86 chipsets</title>
    <para>
        Most modern X86 motherboards share the same configuration
        for memory access, interrupt handling and Input/Output handling.
        How these facilities are organised is described in the chipset.
        Most CPU manufacturers provide a reference implementation of a
        chipset which is guaranteed to work with a specific CPU.
        Third party organisations often choose to enhance this implementation.
    </para>
    <sect2>
    <title>Bridges</title>
    <para>
        The CPU is the central element of the chipset and it is connected
        to other parts through 'bridges'. 
        </para>
        
        <para>
        The high speed North Bridge connects the CPU
        with the RAM and the graphical bus. This bus is clocked at the speed of
        the memory modules and is mostly referred as bus speed, as opposed to 
        processor speed. Multi processor systems have one data bus 
        per processor connected to the North Bridge. A wide system bus allows
        multiple data fetches from main memory. Common implementations provide
        a 128bits wide bus allowing 4 data fetches per clock cycle on 32 bit systems.
        </para>
        
        <para>
        The South Bridge connects the slower peripherals through a 16 or 32 bit bus
        with the North bridge and usually clocks at 33MHz, or 66MHz on newer
        systems. It provides interfaces to hard disks, USB devices and any other
        peripheral one can find on a motherboard. Since all hardware is mapped
        into memory space, the South bridge can easily intercept requests for the
        peripherals by 'listening' to the processors address bus. To prevent
        load on the processor, several enhancements, like Direct Memory Access (DMA)
        are added to allow data transfers over the bus without processor intervention.
</para>

<para>
        It should be clear that realtime programs will want to limit 
        most communication to the
        North Bridge, since the system bus access is highly deterministic. 
        However,peripheral communication with the Ethernet card, the DAQ cards 
        and the web cam are still required and they can only be accessed over
        the South Bridge.
        Application design and use of system facilities, like interrupt
        handlers and DMA, must keep communications with slow devices at pace.
        This will be discussed in the next sections.
        
    </para>
    </sect2>
    <sect2>
    <title>Interrupts and timers</title>
    <para>
       Timers like the very common programmable 8259 Interrupt Control Unit (ICU)
       allow the user to
       execute a certain task periodically with any interval. The timer
       provides a control register for configuration and counter registers
       which can be written to to set the ticking frequency. Each tick
       generates an interrupt which then starts up a piece of code, mostly
       the scheduler of the running kernel. This timer is available on both
       UP and SMP systems. It can be used in two modes : one shot and periodic
       mode. One shot mode is inefficient because of reprogramming
       the timer each time after it fired. The advantage, however, is that 
       the tasks running do not need to have periodicities that are multiples
       of each other, which is inherent with periodic mode.
</para>

<para>
       It is very important for the application programmer to realize that only
       on systems with properly configured timers, deterministic periodicity
       is possible. And even then, the hardware abstraction layer might assign
       a periodicity which is different from the requested one, Especially
       when the timer is run in periodic mode.
</para>

<para>
       As mentioned before, the timer fires periodically an interrupt, which causes a
       lookup in the interrupt table, where a handler resides that calls
       the scheduler. This allows pre-emptive scheduling, meaning that the
       scheduler can always interrupt the currently running task and 
       assign processor time to another task. However, locking mechanisms
       might disable interrupts, and thus the scheduler, or prevent it from
       choosing another task for execution. This kind of locking should only be for 
       small amounts of time in any system.
</para>

<para>
       Each processor from the Pentium on is extended with an 
       Advanced Programmable Interrupt Controller 
       (APIC). On SMP systems, it is mostly referred to as Local APIC 
       to distinguish it from the external I/O APIC, which is not present on 
       UP systems, since there the APIC of the processor is used. 
       The APIC specification allows communication between multiple
       APICs on a private bus, allowing interrupt masking or sending interrupt 
       messages to each other, known as "Inter Processor Interrupt" (IPI).
</para>

<para>
       On our system, the 8259 is routed to the APIC. However, we will configure
       the realtime operating system to use the APIC for timing interrupts and
       device interrupt handling. This is the best solution for dual processor
       systems.
</para>
    </sect2>
    </sect1>
    <sect1>
    <title>Peripheral communication</title>
    <para>
        As mentioned before, all peripherals are behind the South Bridge.
        When data is ready, the card might raise an interrupt to warn the
        processor. Nearly all hardware needs to be specifically instructed
        to generate interrupts. The operating systems kernel must attach
        the correct handler (Interrupt Service Routine, ISR) which should
        read the new data from the device. 
        Before the data can be acquired after an interrupt, 
        the data busses must be free. This is not always the case and
        the processor has to wait for the bus to become free again to
        process the interrupt
    </para>    
    <para>
        Once the ISR has finished its task, 
        further processing of the data is left to the Deferred Service Routine
        (DSR). Depending on OS scheduling policies, the DSR is mostly
        executed before any other thread is scheduled.
</para>

<para>
        The only way to have deterministic communication with peripheral
        devices is to execute all needed operations on the data within
        the ISR. Because no preemptive scheduling is possible while the
        ISR is executed, 
        interrupts may introduce unexpected latencies on running realtime
        tasks. What is mostly done on such systems is that its only tasks
        is gathering realtime data and sending it to another processor
        for post processing. This can happen in multiple stages, loosening
        realtime constraints on every higher level stage through buffering.
    </para>
    <sect2>
    <title>The Data Bus and Direct Memory Access</title>
    <para>
          <ulink url="http://www.infran.ru/TechInfo/BSD/handbook257.html">
          DMA transfers</ulink> can delay interrupts 
        when data is to be fetched and a DMA transfer is in action.
    </para>
    <para>
        The DMA Controller (DMAC) has two modes, burst and cycle stealing. In cycle 
        stealing mode,
        it releases the bus after each transfered byte, in burst mode,
        it holds the bus until the transfer is complete. Bus arbitration is
        set up so that the processor decides
        whether it gives the bus to the DMA Controller but it can not re-acquire
        the bus until the DMAC releases it again. Most CPUs can work further
        on cached data while the DMAC has the bus, but mostly, DMA transfers
        manifestate in slower instruction execution. The DMACs speed has to
        grow equally with the ever fast growing processor clock speeds, or
        its usefulness will diminish since the processor has to wait anyhow
        for the DMA transfer to complete.
    </para>
    </sect2>
    <sect2>
    <title>Using DMA in the presented control system</title>
    <para>
        DMA transfers can be used to transfer data from the web cam to main
        memory or to the connected hard disk for later retrieval. As pointed
        out above, this might have negative influence on the performance
        of the realtime system. Another alternative is to do all the memory
        read and writes in a lowest priority thread through normal Input/Output
        operations. In that case, the transfer will run when no realtime task 
        is happening.
    </para>
    </sect2>
    </sect1>
    <sect1>
    <title>Branch Prediction</title>
    <para>
        Conditional statements are another limit on deterministic program 
        execution. The compiler and the processor can in most cases not
        know in advance whether a statement is true until all its parameters
        are evaluated. This might seem trivial, but all CISC processors have
        pipelines for instruction decoding and execution. This means that
        the next instruction is being decoded when the current is executed.
        Some processors (like the  
        <ulink url="ftp://download.intel.com/design/pentium4/datashts/29864304.pdf"> Pentium 4
         </ulink> ) have large pipelines consisting
        of 20 stages 
        . Waiting 20 instructions long before knowing
        which instruction to fetch next becomes in that case pretty hard.
        </para>
        
        <para>
        Most processor manufacturers try to eliminate this
        problem by implementing branch prediction algorithms into the
        processor. Simple algorithms might choose for example to decode 
        the path that was chosen most, the last N loop cycles. Doing alternate
        things in a loop might kill performance on such systems. Failing
        to take the right branch is called 'Pipeline Thrashing'.
</para>

<para>
        Another solution is to implement two decoding pipelines which 
        decode both paths. When the correct path is known, the other
        is trashed and filled with a new potential path.
        </para>
        
        <para>
        Experience of the last years led to the belief that it is better to
        keep the pipelines short (10 or less stages) and not to rely on
        branch prediction algorithms too much yet.
</para>

<para>
        The reason why manufacturers have implemented such large pipelines
        are doubtful. A smaller stage can execute its operation on the 
        instruction faster, which can lead to faster processor clock speeds.
        Branch misses, however, can lead to tremendous trashing of the
        pipelines and causes a drop in the effective clock frequency.
    </para>
    </sect1>
    <sect1>
    <title>Caching</title>
    <para>
        The modern X86 processors
        have two caches on board, a fast and small Level 1 cache which 
        fetches one word per clock tick and a slower, larger Level 2
        cache which operates at a lower frequency. On a cache miss in the
        L1 cache, an attempt is made to retrieve the data from the L2
        cache, if that fails too, the data is retrieved from main memory.
        In non realtime systems, data can also be missing from main memory
        and found on a hard disk or another storage device. 
</para>

<para>
        Since one must always work with worst case scenarios (meaning 
        cache misses) when programming
        realtime systems, caches are omitted on most embedded systems.
        All modern X86 processors have large caches which intelligent compilers
        try to use in an efficient manner.
    </para>
    </sect1>
    <sect1>
    <title>Conclusions</title>
    <para>
        Caching, branch prediction and DMA transfers might delay execution
        for indeterminate time and make it harder to estimate
        worst case scenarios. Long pipelines, cache and DMA data transfers
        are therefore to be avoided in choosing hardware whenever possible.
        However, our chosen hardware configuration has all these options.
        For the processor operation involving cache and the pipeline, we
        could try to define a worst case scenario and test the software
        against that. DMA data transfers can be avoided by not invoking
        it and leaving the DMAC on the motherboard unused.
    </para>
    </sect1>
    </chapter>
    <chapter>
    <title>Realtime Operating Systems</title>
    <para>
        This chapter discusses 2 micro kernels implementations and a 
        full realtime operating system.
    </para>
    <sect1>
    <title>Micro Kernels</title>
    <para>
        The concept of micro kernels emerged in the mid 1980's as an
        alternative to large monolithic Unix kernels. The idea is to only
        put minimal functionality in the kernel and implementing device
        drivers etc outside the kernel. The  <ulink url="http://www.gnu.ai.mit.edu/software/hurd/gnumach.html"> GNU Mach micro kernel
         </ulink>, which
        is used by the Hurd project is an example
        . Until now, the success
        of micro kernels is limited and monolithic kernels form the vast
        majority of the installed kernels.
</para>

<para>
        In realtime systems, a micro kernel is added between the normal
        kernel and hardware interrupts, where the normal kernel runs as the
        lowest priority task. All calls to interrupts in the normal kernel
        are software emulated by the micro kernel. 
</para>

<para>
        The advantage of using micro kernels under a normal kernel
        lies in the fact that development can happen completely on the 
        target machine. One only has to issue a command to insert a
        new realtime program into the micro kernel.
        Most embedded systems require uploading of the
        software for immediate execution at boot time. 
        A disadvantage of the micro kernel
        is that rebooting the development platform is required also
        when the realtime application crashes.
    </para>
    <sect2>
    <title>RTLinux</title>
    <para>
        Victor Yodaiken, the creator of RTLinux was the first to use the
        concept of a micro kernel under the Linux kernel to obtain realtime
        scheduling. He obtained a 
        <ulink url="http://www.thinkingnerds.com/fsmlabs/PATENT.html"> patent 
        </ulink> on this technology which validity has been 
        <ulink url="http://www.linuxdevices.com/articles/AT2094189920.html">
        questioned a few times
        </ulink>. The patent describes how they invented the "deferred interrupt
        technique" which emulates hardware interrupts in the micro kernel.
</para>

<para>
        RTLinux is a product of FSMLabs and was in November 2001 split into
        a Free and a non free version. Because of this, the Free implementation
        has not been updated recently and is stuck at the 3.1 version number.
</para>

<para>
        RTLinux has the philosophy that all features should never obstruct
        realtime operation.  Hence, dynamic memory allocation, RTTI, RPC and 
        realtime execution of user space programs are not present. The Free version
        of RTLinux supports C++ code but because of dynamic memory allocation
        restrictions, limits the applicable software patterns.
</para>

<para>
        The Standard Template Library (STL) is not supported but can be used
        with minor modifications. iostreams are not supported at all.
        
    </para>
    </sect2>
    <sect2>
    <title>RTAI</title>
    <para>
        RTAI has a 
        <ulink url="http://www.aero.polimi.it/~rtai/documentation/articles/history/">
        long history 
        </ulink> 
        with its roots in the DOS environment.
        With the dawning of RTLinux and the Linux kernel progressing towards the
        2.2.x series, realtime became a possibility in Linux. RTAI was worked
        on roughly in parallel with RTLinux, but had in the end its own
        implementation of the software patent. At first RTAI mimicked the
        functionality of RTLinux and still provides a compatibility layer,
        but when the RTLinux API changed to the realtime POSIX specification,
        both projects choose another path. RTAI specified its own interface
        and added later on a POSIX compliant interface to its native 
        functionality. 
</para>

<para>
        RTAI is very feature rich and leaves it to the application programmer
        to decide whether or not to give up determinism in a certain realtime
        task. An example is dynamic memory allocation which might block for
        an undefined time period. However, by using these methods only in
        specific (soft realtime) threads, one has many more possibilities
        at his disposal for solving software problems.
</para>

<para>
        RTAI tries to implement a C++ framework for realtime tasks together
        with a subset of the STL iostreams library.
        </para>
        
        <para>
        Sloppy interfaces and an unpredictable development path are considered
        as RTAIs major drawback. They refuse to separate stable from unstable
        development, probably to reduce maintenance costs. However, this
        puts the costs on the shoulders of the users. In the end, the
        unstable RTAI releases only contain few bugs which are mostly fixed
        within hours of reporting. A full reordering of interfaces, aimed
        at consistency, and consequential reordering of header file dependencies
        would result in a far more comprehensible and extendible framework.
    </para>
    </sect2>
    </sect1>
    <sect1>
    <title>Embedded Realtime Kernels</title>
    <para>
        On small embedded systems, kernel and application are linked into a
        single image which is uploaded to the target system and started
        immediately at boot time. It requires cross compiling on the 
        development platform and the standard libraries for the target.
        Most embedded realtime operating systems have very well defined 
        clean interfaces, since they do not drag along any legacy code.
    </para>
    <sect2>
    <title>eCos</title>
    <para>
        eCos is an embedded realtime operating system written in C++. Therefore
        it supports a subset the standard C++ library and allows high level
        programming of the device. STL implementations have been 
         <ulink url="http://sources.redhat.com/ml/ecos-discuss/2000-04/msg00200.html">
         reported</ulink> to work, excluding iostreams.
        </para>
        
        <para>
        It was until recently supported by Red Hat
        Linux but is now maintained in the public domain.
</para>

<para>
        eCos is a single process multi threaded operating system, meaning that
        all threads share the same address space, as is the case in the Linux
        kernel. eCos has the ISO standard C and math library. It does not support
        exceptions and has implemented its own exception handler. It should also
        be noted that memory management is left to the application developer.
</para>

<para>
        eCos still profits from the earlier Red Hat support, resulting in up to date
        documentation and tutorials.
    </para>
    </sect2>
    </sect1>
    <sect1>
    <title> Conclusions </title>
    <para>
        eCos might be considered as the most mature realtime operating system 
        discussed here, but in a way, also the most limited with respect to
        user interaction. RTAI and RTLinux can run together with a full
        GNU/Linux distribution and profit from all the tools available (GUIs,
        device drivers, ...). Since all three OS's tend to implement POSIX compliant
        libraries, writing software that works on all three should prove
        trivial. 
        </para>
        
        <para>
        Exceptions, dynamic memory allocation and RTTI are supported
        at different degrees, but RTAI seems the only one with full potential
        to support them the most because of the software memory management 
        module. With this power comes also the possibility to give up
        deterministic execution in a task. 
        </para>
        <para>
        RTAI is chosen because it offers the most features we need. The webserver
        can run as a user process under the low priority Linux kernel. This 
        guarantees immediately that it will never interfere with the realtime
        control task. If the system should prove to be under dimensioned, than
        the webserver will degrade gracefully first before the system might fail
        reaching the deadlines.
    </para>
    </sect1>
    </chapter>
    <chapter>
    <title> Software Patterns for Realtime Operating Systems</title>
    <para>
        This chapter presents some object oriented solutions for use in
        realtime systems, taking in account all the governing restrictions.
    </para>
    <sect1>
    <title>Restrictions</title>
    <para>
        As pointed out in the previous chapter, the realtime operating systems
        limit dynamic memory allocation, exceptions and Run Time Type
        Information (RTTI). However, the only true restrictive element is dynamic
        memory allocation, since RTTI is platform agnostic and exceptions
        propagation can be analysed on beforehand in
         <ulink url="http://std.dkuug.dk/jtc1/sc22/wg21/docs/papers/2002/n1359.pdf">
        some cases </ulink>. I refer to that paper for a very thorough analysis
        of C++ in realtime systems.
    </para>
    </sect1>
    <sect1>
    <title>Operating System Abstraction</title>
    <para>
        Portability goes hand in hand with standards. POSIX, OpenGL, HTML,...
        are all standards that allow cross platform software to be developed
        because of unified specifications. However, the realtime operating
        systems discussed above all three were compliant to a certain degree
        in implementing the POSIX, ISO C or C++ standard libraries. The 
        most limiting factor was that all kernel interfaces were in C
        and no C++ framework was provided. This is not surprising since
        there is no C++ API for system calls. 
    </para>    
    <para>
        A clean design would first try
        to compensate for lack of features in the underlying OS by implementing
        an emulation in a separate layer. We call this layer the Framework
        Operating System Interface and it tries to provide interfaces to
        the POSIX, ISO C and standard C++ libraries, as if you were working
        in a normal development environment. Additionally, we extended these
        C function interfaces with C++ interfaces to threads, mutexes,
        condition variables and so on. It must be noted that there is no 
        standard yet for these interfaces, but they resemble the <ulink url="http://www.rtj.org/"> Java Realtime</ulink> specification
        closely. 
     </para>
     <para>   
        To have a cleaner design we wrapped most POSIX calls to C++ classes.
        Constructors and destructors were used to cleanly initialize and
        clear data structures, while the class itself protected access
        to the data members. An example are the Mutex and MutexLock classes.

	  <programlisting>
	    <![CDATA[
class A
{
    Mutex theLock; // wraps a pthread mutex
//...
public:
    void foo()
    {
        // start critical section
        MutexLock locker(theLock); // lock mutex upon construction
        // ... access shared data
        // end critical section
    }                              // locker is destroyed, mutex unlocked
};
]]>
	  </programlisting>

        We use the Mutex class to protect all access between any of the above
        threads. As one can see in the above example, the use of the Mutex
        is completely encapsulated.
    </para>
    <para>
        Encapsulating knowledge on how
        the operating systems primitives have to be used has proven to be
        very useful and reduced programming errors by novices.
    </para>
    </sect1>
    <sect1>
    <title>Placement new and delete</title>
    <para>
        Data is encapsulated in objects, initialized on construction time
        and freed on destruction time. Most data is not yet known on compile
        time and needs instantiation when the program is running. This is
        only possible if memory management is supported by the RTOS, and 
        even then, it will degrade or eliminate deterministic behaviour.
        Allocating memory on beforehand for a certain data structure
        allows to work around this problem. The C++ language operators
        <function>placement new</function> and <function>placement delete</function>  
        provide the interface
        <ulink url="http://www.glenmccl.com/nd_cmp.htm">for such operations</ulink> . 
        We use them in path planning where a piece of memory is reserved
        for every known type of path (circle, line etc) and a 
        pointer to a polymorphic base class is used to operate on the 
        specific instances.
    </para>
    </sect1>
    <sect1>
    <title>Threads</title>
    <para>
        POSIX threads are the best well known thread specification. Threads
        are only needed when a part of the program has to wait while another
        needs guaranteed periodical execution. Multimedia applications, where
        one part reads from the hard disk and another broadcasts the 
        information stream at a fixed frequency (to a display, a sound card)
        are good examples. Web servers where each thread listens to a number
        of sockets are another good example. It is harder to find such good
        examples in realtime control. Mainly because blocking is nowhere done
        and secondly each task needs a fixed execution time per period
        anyway. Allowing threads to concurrent each other is a waste of 
        scheduling and locking time. It is easier to perform all tasks very
        fast sequentially each time period.
    </para>
    <para>
        One should carefully investigate the cases where threads are needed, 
        for example to decouple hard realtime from soft realtime or execute 
        tasks with different periodicity. In the realtime control system, 
        only three threads are used.  See <ulink url="simple-overview.png">
        this picture</ulink>, for a diagram.
    </para>
<informalfigure>
<mediaobject>
<imageobject>
<imagedata fileref="ThreadOverview.png" srccredit="PS,2002"/>
</imageobject>
<textobject><phrase>A schematic thread overview</phrase></textobject>
<caption><para>Each thread is bound to one processor. The users pace
applications run at the lowest priority.
</para>
</caption>
</mediaobject>
</informalfigure>
        <sect2>
        <title>The Asynchronous Operation Processor (AOP)</title>
        The first thread is used for doing all soft realtime tasks.
        One can request it to execute a certain functionality. This request
        is queued and when no other hard realtime task is running, all
        queued requests are executed. Communication
        between not realtime and soft realtime can be done in this thread
        and is done by the Command Interpreter component. 
        Text commands are sent 
        from the not realtime process and lead to instantiation of objects 
        in the
        AOP thread using the Factory Method and Command
        software patterns. This instantiation might block, but a batch
        mode allows to create first all commands and then execute them
        at the time needed. This thread runs on the non-realtime processor.
        </sect2>
        <sect2>
        <title>The Position Control Loop</title>
        Position control includes inverse and forward kinematics
        and Cartesian path interpolation. Position control is executed at
        a 100Hz frequency in realtime. The commands of the command interpreter
        might re-program the path the robot has to follow. While reprogramming,
        the path planner emits the last position as set point. The steering
        signals of the position control loop are sent to joint level 
        interpolators which interpolate between different velocity set points.
        This thread runs on the realtime processor.
        </sect2>
        <sect2>
        <title>The Joint Interpolators</title>
        A 6 degrees of freedom robot has 6 joints. Each joint gets a velocity
        set point from the position control loop every 10ms. Each joint control
        loop operates at a frequency of 1kHz and thus has to interpolate
        velocity set points between consecutive reference signals of the
        positional loop (in this case 9 interpolations). Since no calculation
        is blocking, each joint calculation happens 
        in the same thread which runs at 1kHz, and each calculates a new
        velocity setpoint per period.
        The communication between the Position Control Loop and the 
        Joint Interpolators do not need necessarily be protected by mutexes
        because this thread runs also on the realtime processor, which means that
        never both threads can access the data simultaneously. This is under
        the assumption that the scheduler did not preempt the running task.
        This can be accomplished by 'cooperative scheduling', allowing the
        task to inform the scheduler that it can be put to sleep until the
        next execution period.
        </sect2>
    </sect1>

    <sect1>
    <title>Sensor Data Acquisition </title>
    <para>
        The main sensors of the system are positional encoders. They provide
        the radial position of each joint of the robot. The control loops
        have to work with the most recent data available and therefore,
        it is better to place the acquisition cards in the same system
        as where the steering signal for the joints is calculated.
        When for some reason, data acquisition is not possible on the main
        system, only the deterministic CAN bus would be sufficient to comply
        with the timing constraints.
    </para>
    <para>
        The hard realtime threads will pull the data from the PCI cards when
        needed. The disadvantage of this approach is that this will introduce 
        latencies because of the slower communication over the South Bridge.
        That could be avoided by caching all sensor data and refreshing it in
        another thread. This has the disadvantage that the data can have
        aged. All data should always represent a consistent snapshot of
        the system. The possibly slow SSI communication protocol could 
        also need an extra thread to overcome the long processing time of the
        data pull action.
    </para>
    </sect1>
    <sect1>
    <title>Local or Distributed Data</title>
    <para>
        Delays in sensor readings because of distributed acquisition,
        will introduce instability in the system very fast. 
        It is better to use remote commands which express the intention
        of the operator, but let the action itself take place at the processor
        closest to the robot hardware. As one could see, the
        Command Interpreter has exactly this task. It is in exactly the
        same way that networked components should work. The whole control
        component, which is responsible for the precise tracking of the
        robot, should work closely with the sensors and reside on one
        system. On this system, it presents an interface from where it can
        accept commands from remote, higher level components.
        Our choice for an SMP system to process all realtime data confirms
        this design choice.
    </para>
    </sect1>
    
    <sect1>
    <title>Events and States</title>
	<para>
	  Events are implemented using the <interface>Observer</interface> design 
      pattern. A class which wants to be notified
	  of events, has to implement the  <interface>EventListenerInterface
      </interface>, in which the <function>handleEvent(EventInterface*)
      </function> method will be called when the event occurs i.e. is 'fired'. 	
    </para>
        <para>
        The <interface>EventListener</interface> can decide to call the event 
        completer(if available)
        by calling the <function>complete(EventListenerInterface*)</function>
        function on the <interface>Event</interface> object.  
        <interface>EventListener</interface> and completer can be
        different or the same objects. We can categorise event handling and
        completion in two categories: synchronous and asynchronous, both
        possible for handling and completion. This leaves four types of events :
        <itemizedlist>
        <listitem><para>Synchronous event handling, synchronous completion (think separate components)</para></listitem>
        <listitem><para>Synchronous event handling, asynchronous completion (think interrupts)</para></listitem>
        <listitem><para>Asynchronous event handling, asynchronous completion (think mission to Mars)</para></listitem>
        <listitem><para>Asynchronous event handling, synchronous
completion (think separate components on Mars)</para></listitem>
        </itemizedlist>
        </para>
        <para><emphasis>
        The aim of this separation of listener and completer is decoupling: both
        can be implemented in different objects and do not know about each other. Even
        more, the completer should not count on the fact that it is called each time
        the listener is called. It is possible that in some cases the listener asks for
        completion, and in other cases does not require it (yet).</emphasis>
        </para>
    <para>
        Events have big potential. I will not go further into detail in this paper
        about their possibilities, but they can provide many forms of IPC
        together with Finite State Machines and Petri nets. Explaining these
        mechanisms would be out of the scope of this paper.
    </para>
    <sect2>
    <title>Applying Events to the control system</title>
    <para>
        Events can be put in many places in the control system. 
        Two places where events are crucially important are emergency stops
        and user communication.
    </para>
    <para>
        The "Emergency Stop" event will be fired whenever a serious error condition
        occurs. This will be of the synchronous handling - asynchronous 
        completion event type. First all listeners will be notified that an emergency
        stop has to be performed and all components go to a safe state. The
        robot will disable the motor amplifiers and enable the breaks and so on.
        Next, when every component has done this transition, secondary, less critical
        operations can be completed, for example, informing the user that something
        went wrong and diagnostics information.
    </para>
    <para>
        The second example is where an event is fired each time a command arrives
        from the user so that the robot receives a new task. This event will be fired by
        the buffer receiving the commands and thus notifying the command interpreter.
        This component will then take further action, resulting in the execution of 
        a new task
    </para>
    <para>
        As can be seen from these two examples, the firing of an event actually
        indicates that the system should change its state, and all relevant components
        are thus notified and can take appropriate action. This decoupling of who 
        decides when to change state and the components executing this decision is
        important for a clean design.
    </para>
    </sect2>
    </sect1>
    <sect1>
    <title>Non realtime processes </title>
    <para>
        The realtime control system merely executes tasks given from the non realtime
        processes. These processes reside in the normal Linux process tree. The 
        'touching' application acquires the force sensor data and sends new motion
        commands to the command interpreter. With each new measurement, the model
        of the object to be investigated can be updated until enough certainty 
        is reached about the shape of the object. Meanwhile, the webserver
        accesses the web cams data and sends it to its clients over the Ethernet
        network.
     </para>
     </sect1>
    <sect1>
    <title> Conclusions </title>
    <para>
        Software patterns and object oriented programming allow to build a
        realtime system with high language constructs. A minimum of threads
        should be used in a realtime program. Events allow many kinds of
        communications and asynchronous operations can be used to 
        dynamically construct objects. The tasks were sorted from high
        priority to low priority, depending on the impact of deadline failure
        of the task.
     </para>
     </sect1>
    </chapter>

<bibliography>
<title>Bibliography</title>
<biblioentry id="Lisk88" xreflabel="Lisk88">
  <authorgroup>
    <author><firstname>Barbara</firstname><surname>Liskov</surname></author>
  </authorgroup>
  <title>Data Abstraction and Hierarchy</title>
    <seriesinfo>
        <title> SIGPLAN Notices</title>
        <seriesvolnums>23 (5)</seriesvolnums>
    </seriesinfo>
</biblioentry>
<biblioentry id="Gang94" xreflabel="Gang94">
  <authorgroup>
    <author><firstname>Erich</firstname><surname>Gamma</surname></author>
    <author><firstname>Richard</firstname><surname>Helm</surname></author>
    <author><firstname>Ralph</firstname><surname>Johnson</surname></author>
    <author><firstname>John</firstname><surname>Vlissides</surname></author>
  </authorgroup>
  <title>Design Patterns Elements of Reusable Object-Oriented Software</title>
    <copyright><year>1994</year>
             <holder>Addison-Wesley</holder></copyright>
</biblioentry>
</bibliography>
</book>

        
