<?xml version='1.0'?>

<!DOCTYPE article PUBLIC "-//OASIS//DTD DocBook XML V4.1.2//EN"
"/usr/share/sgml/docbook/dtd/xml/4.1.2/docbookx.dtd"
[
<!ENTITY orocos      "<acronym>Orocos</acronym>">
<!ENTITY rtai        "<acronym>RTAI</acronym>">
<!ENTITY rtos        "<acronym>RTOS</acronym>">
]
>

<article>
  <articleinfo>
    <title>The Orocos Core Library Manual</title>
    <authorgroup>
      <author>
	<firstname>Peter</firstname>
	<surname>Soetens</surname>
	<affiliation>
	  <orgname>K.U.Leuven</orgname>
	  <address><country>Belgium</country></address>
	</affiliation>
      </author>

      <author>
	<firstname>Herman</firstname>
	<surname>Bruyninckx</surname>
	<affiliation>
	  <orgname>K.U.Leuven</orgname>
	  <address><country>Belgium</country></address>
	</affiliation>
      </author>
      
      <author>
	<firstname>Panagiotis</firstname>
	<surname>Issaris</surname>
	<affiliation>
	  <orgname>K.U.Leuven</orgname>
	  <address><country>Belgium</country></address>
	</affiliation>
      </author>
    </authorgroup>
    <copyright>
      <year>2002-2005</year>
      <holder>Peter Soetens, Herman Bruyninckx</holder>
    </copyright>

    <abstract>
      <para>
	This document explains the design and implementation of the
	<emphasis>Core Library</emphasis> of &orocos;, the <emphasis>Open
RObot COntrol Software</emphasis> project. The CoreLib provides
infrastructural support for the functional and application components
of the &orocos; framework.
      </para>
    </abstract>

    <revhistory>
      <revision>
	<revnumber>0.01</revnumber>
	<date>22 Aug 2002</date>
	<authorinitials>hb</authorinitials>
	<revremark>Initial version</revremark>
      </revision>
      <revision>
	<revnumber>0.9</revnumber>
	<date>11 Nov 2002</date>
	<authorinitials>ps</authorinitials>
	<revremark>lots of updates</revremark>
      </revision>
      <revision>
	<revnumber>0.11</revnumber>
	<date>29 Oct 2003</date>
	<authorinitials>ps</authorinitials>
	<revremark>Stripped Devices and OS parts</revremark>
      </revision>
      <revision>
	<revnumber>0.12</revnumber>
	<date>2 Apr 2004</date>
	<authorinitials>ps</authorinitials>
	<revremark>StateContext updates</revremark>
      </revision>
      <revision>
	<revnumber>0.13</revnumber>
	<date>18 May 2004</date>
	<authorinitials>ps</authorinitials>
	<revremark>Change in the StateContext interface</revremark>
      </revision>
      <revision>
	<revnumber>0.14</revnumber>
	<date>2 June 2004</date>
	<authorinitials>ps</authorinitials>
	<revremark>Clarified some parts based on feedback</revremark>
      </revision>
      <revision>
	<revnumber>0.18</revnumber>
	<date>10 Dec 2004</date>
	<authorinitials>ps</authorinitials>
	<revremark>New Event Implementation and Simulation Thread. Reordering and cleanup of Sections.</revremark>
      </revision>
      <revision>
	<revnumber>0.18.1</revnumber>
	<date>5 Jan 2005</date>
	<authorinitials>ps</authorinitials>
	<revremark>Added Logging Framework.</revremark>
      </revision>
      <revision>
	<revnumber>0.20.0</revnumber>
	<date>31 Jan 2005</date>
	<authorinitials>ps</authorinitials>
	<revremark>Added DataObject section within Buffer section.</revremark>
      </revision>
    </revhistory>

    <legalnotice>
      <para>
	Permission is granted to copy, distribute and/or modify this document
	under the terms of the GNU Free Documentation License, Version 1.1 or
	any later version published by the Free Software Foundation, with no
	Invariant Sections, with no Front-Cover Texts, and with no Back-Cover
	Texts. A copy of this license can be found at
	<ulink
	  url="http://www.fsf.org/copyleft/fdl.html">http://www.fsf.org/copyleft/fdl.html</ulink>.
      </para>
    </legalnotice>

  </articleinfo>

  <sect1>
    <title>Introduction</title>
    <para>
      This section describes the semantics of the services
      available in the &orocos; CoreLib Package.
    </para>
    <para>
      The Orocos OS package allows &orocos; users to build their software 
      on all supported systems with only a recompilation step.  
      This library, the CoreLib, provides fully thread-safe C++ implementations for (periodic) tasks, 
      synchronous/asynchronous Events, time measurement, simulations and 
      provides interfaces which are common for all realtime services.
      The CoreLib imposes a hard realtime <emphasis>architecture</emphasis>. 
      <emphasis>
	The goal of this fixed architecture is to keep 
	applications deterministic, by avoiding the classical pitfalls of
	letting application programmers freely choose the priorities of their
	tasks, and their communication primitives. Practice has indeed showed
	that most programmers do not succeed in strictly decoupling the
	functional and algorithmic parts of their code from the OS-specific
	primitives used to execute them.</emphasis>
    </para>
    <para>
      Of course, the realtime performance depends not only on
      the underlying operating system 
      <emphasis>but also on the hardware.</emphasis> Hardware devices are abstracted
      in the Orocos Device Interface package.
    </para>
    <para>
      The following sections will first introduce the reader to creating
      (periodic) Tasks in the system. Furtheron, they are extended
      with Events. The following sections explain usefull classes which
      are used throughout the framework such as the HeartBeatGenerator,
      Properties, StateContexts, Commands, Conditions and the object
      NameServer.
    </para>
  </sect1>
  <sect1>
    <title>Periodic and non Periodic Tasks</title>
    <para>
      Threads are the major cause of headaches in multithreaded
      systems programmers heads. Synchronisation, data protection,
      priority tweaking and resource locking must all be done very
      carefully and mostly lead to suboptimal solutions. Even more,
      the predictability of the system highly decreases with the
      introduction of more threads or interactions between threads.
      This section gives an introduction to defining periodic tasks
      which run together with other periodic tasks of the
      same priority in the same periodic thread. Non 
      periodic tasks can run in these threads or are implemented
      using a non periodic thread.
    </para>
    <sect2>
      <title>Periodic Tasks Run in Periodic Threads</title>
      <para>
	For most basic control applications, a high priority periodic thread
	and a low priority periodic thread are enough. The high priority thread is
	used for all periodic tasks that need to be executed atomically. No
	action in this thread will ever be pre-empted. The low
	priority realtime thread is used for all periodic tasks which may be
	interrupted but still have hard deadlines. It can always be
	preempted by the high priority thread. There is also a non
	realtime periodic thread which gives no deadline guarantees. 
	Orocos provides implementations for these three threads 
	( which only differ in periodicity and priority ) and allows
	to extend to more for your specific needs.
      </para>
    </sect2>
    <sect2>
      <title>Creating a Periodic Thread</title>
      <para>
	Orocos provides, by default, two hard realtime periodic threads and
	a non realtime periodic thread. The <classname>ZeroTimeThread</classname>
	has the highest priority, the <classname>ZeroLatencyThread</classname>
	has a lower priority and the <classname>NonRealTimeThread</classname>
	has an even lower priority is not realtime at all (but still periodic).
	If they are needed, Orocos will create and start/stop them automatically,
	thus the user does not need to know or take care of them.
      </para>
      <para>
	For users needing to solve multi-threaded control problems, the
	PriorityThread is provided with which you
	can create an arbitrary number of threads with no more than
	one thread per priority level. It needs a bit more setup than
	the standard Orocos threads, since you still have to set the
	priority and start the thread. An example is given below. 
	A PriorityThread is not automatically started like the ZeroTimeThread,
	ZeroLatencyThread and NonRealTimeThread. It must be done by the
	user. Furthermore, The PriorityThread is the general case of the
	above three cases, since its priority can match their priorities
	as given in the configuration tool.</para>
      <para>
	<example>
	<title>Example Periodic Thread Creation</title>
	<para>
	    This example shows how to create the PriorityThread.
	</para>
	<programlisting><![CDATA[
#include "corelib/PriorityTask.hpp"

using namespace ORO_CoreLib;

class KineLoop : public RunnableInterface
{
    bool initialize() { // ...
    }
    void step() {
    }
    void finalize() {
    }
    // ...
};

ORO_main( int argc, char** argv)
{
  // Define your tasks (see later)
  KineLoop kine_loop;

  // An extra thread for low priority tasks
  // 9 : The priority.
  // 0.01 : The period.
  // You have to manually start the thread.
  PriorityThread<9>::Instance()->periodSet( 0.01 );
  PriorityThread<9>::Instance()->start();
  // Optional :
  PriorityThread<9>::Instance()->makeHardRealtime();

  // This task is run in the extra thread above,
  // kine_loop inherits from RunnableInterface :
  PriorityTask<9> own_task( 0.05, &kine_loop ); // 0.05 is multiple of 0.01

  own_task->start();

  // ...

  own_task->stop();

  return 0;
}
]]>
	</programlisting>
      </example>
      </para>
    </sect2>
    <sect2>
      <title>Creating a Periodic Task</title>
      <para>
	If you want to execute functionality in one of the Orocos threads, you need to 
	create a Task of a certain type, depending on the thread type. The table
	below summarises which Task type there is per thread.
	<table>
	  <title>Thread and Task summary</title>
	  <!-- one of (graphic mediaobject tgroup) -->
	  <tgroup cols="2">
	    <thead>
	      <row>
		<!-- one of (entrytbl entry) -->
		<entry>Thread</entry>
		<entry>Task</entry>
	      </row>
	    </thead>
	    <tbody>
	      <row>
		<entry>ZeroTimeThread</entry>
		<entry>TaskNonPreemptible</entry>
		<!-- one of (entrytbl entry) -->
	      </row>
	      <row>
		<!-- one of (entrytbl entry) -->
		<entry>ZeroLatencyThread</entry>
		<entry>TaskPreemptible</entry>
	      </row>
	      <row>
		<!-- one of (entrytbl entry) -->
		<entry>NonRealTimeThread</entry>
		<entry>TaskNonRealTime</entry>
	      </row>
	      <row>
		<!-- one of (entrytbl entry) -->
		<entry>PriorityThread&lt; N &gt;</entry>
		<entry>PriorityTask&lt; N &gt;</entry>
	      </row>
	      <row>
		<!-- one of (entrytbl entry) -->
		<entry>SimulationThread</entry>
		<entry>SimulationTask</entry>
	      </row>
	    </tbody>
	  </tgroup>
	</table></para>
      <para>
	There are two ways to run functionality in a periodic task. By :
	<itemizedlist>
	  <listitem>
	    <para>
	      Implementing the <classname>RunnableInterface</classname>  in another class
	      ( functions initialize, step and finalize ). The RunnableInterface object (i.e. run_impl) can
	      be assigned to a task using <synopsis> task.run( &amp;run_impl )</synopsis> or
	      at construction time of a Task : <synopsis> TaskNonPreemptible task( period, &amp;run_impl );</synopsis>.
	      <programlisting>
  #include &lt;corelib/RunnableInterface.hpp>
  #include &lt;corelib/TaskNonPreemptible.hpp>

  class MyPeriodicTask
	: public ORO_CoreLib::RunnableInterface
  {
  public:
    // ...
    bool initialize() {
       // your init stuff
       double myperiod = this->getTask()->periodGet();
       // ...
       return true; // if all went well
    }

    void step() {
       // periodic actions
    }

    void finalize() {
       // cleanup
    }
  };

  // ...
  MyPeriodicTask run_impl;

  TaskNonPreemptible task( 0.01 ); // 100Hz
  task.run( &amp;run_impl );
  task.start();

  // etc...  </programlisting>
	    </para>
	  </listitem>
	  <listitem>
	    <para>
	      Inheriting from a Task class and overriding the initialize, step
	      and finalize methods.
	      <programlisting>
  class MyOtherPeriodicTask
      : public TaskNonPreemptible
  {
  public :
    MyOtherPeriodicTask()
      : TaskNonPreemptible( 0.01 ) // 100Hz
    {
    }

    bool initialize() {
       // your init stuff
       double myperiod = this->periodGet();
       // ...
       return true; // if all went well
    }

    void step() {
       // periodic actions
    }

    void finalize() {
       // cleanup
    }
	// ...
  };

  // When started, will call your step
  MyOtherPeriodicTask task;
  task.start();  </programlisting>
	    </para>
	  </listitem>
	</itemizedlist>
	The Task will detect if it must run an external RunnableInterface. If none
	was given, it will call its own virtual methods.
      </para>
    </sect2>
    <sect2>
      <title>Periodic Task Ordering</title>
      <para>
	Periodic Tasks are executed <emphasis>in the order as they are started</emphasis>.
	The periodic thread responsible
	for the Task will execute all tasks one after the other, respecting
	the periodicity of the periodic task. This means that a Task with a lower periodicity
	of the thread (e.g. 10 times lower) will only be called a fraction of the
	time (thus every 10th period), still respecting the ordering.
      </para>
      <para>
	<figure><title>Execution sequence diagram</title>
	  <mediaobject>
	    <imageobject role="html">
	      <imagedata fileref="execution-sequence.png" format="PNG"/>
	    </imageobject>
	    <imageobject role="fo">
	      <imagedata fileref="execution-sequence.eps" format="EPS"/>
	    </imageobject>
	    <!--
	    <caption><para>
	  </para></caption>
	    -->
	  </mediaobject>
	</figure>
      </para>
    </sect2>
    <sect2>
      <title>Example Periodic Task Creation</title>
      <example>
	<title>Example Periodic Task Creation</title>
	<para>
	  This example shows how all kinds of tasks can be created. When a task
	  is started it will add itself to the correct thread.
	</para>
	<programlisting><![CDATA[
#include "corelib/TaskNonPreemptible.hpp"
#include "corelib/TaskPreemptible.hpp"
#include "corelib/TaskNonRealTime.hpp"
#include "corelib/PriorityTask.hpp"

using namespace ORO_CoreLib;

ORO_main( int argc, char** argv)
{
  // Define your tasks

  // ...

  // These tasks are run in the Orocos Thread Model
  TaskNonPreemptible fast_task1(0.001, &vel_loop);
  TaskNonPreemptible fast_task2(0.001, &vel_loop);

  TaskPreemptible slow_task(0.01, &pos_loop);
  TaskNonRealTime nrt_task( 0.1, &display_server );

  // This task is run in the extra thread above
  PriorityTask<9> own_task( 0.05, &kine_loop ); // 0.05 is multiple of 0.01

  // All is transparant from here on.
  fast_task1->start();
  fast_task2->start(); // is always run directly after fast_task1 !
  slow_task->start();
  own_task->start();
  nrt_task->start();

  // ...

  fast_task1->stop();
  fast_task2->stop();
  slow_task->stop();
  own_task->stop();
  nrt_task->stop();

  return 0;
}
]]>
	</programlisting>
      </example>
    </sect2>
    <sect2>
      <title>Periodic Threads Overview</title>
      <para>
	The high priority thread is the
	<classname>ZeroTimeThread</classname>. It will execute all
	<classname>TaskNonPreemptible</classname> Tasks
	synchronically. You can create your own not preemtable task by
	inheriting from this class. Its name is derived from the fact
	that some tasks need to be executed in an infinite small
	amount of time to work correctly. Control loops are an example
	of this. To come as close as possible to this (impossible)
	constraint, we make sure that the task is never preempted by
	another task and thus is executed 'atomically'.
      </para>
      <para>
	The low priority tasks are executed by the
	<classname>ZeroLatencyThread</classname> class. It will
	execute all <classname>TaskPreemptible</classname> Tasks
	sequentially, when no non-preemptible tasks are executed.
	Every <classname>TaskPreemptible</classname> can be preempted
	by a <classname>TaskNonPreemptible</classname> but not by
	another <classname>TaskPreemptible</classname>. The
	ZeroLatencyThread has this name because the zero time
	constraint is dropped, but replaced by the constraint that no
	latency may occur and thus, execution is still realtime.
	Again, to satisfy this constraint, only deterministic time
	operations may be done in this thread.
      </para>
      <para>
	For not realtime executions, as there are userspace
	communication, memory allocations,... we use the
	NonRealTimeThread. Roughly put, you can do
	<emphasis>anything</emphasis> in this thread, as long as it
	takes finite time. This is the lowest priority thread in the
	system and it should never lock a resource of the realtime
	thread. Tasks being executed in the NonRealTimeThread are
	called <classname>TaskNonRealTime</classname>.
      </para>
      <para>
	The last standard thread type Orocos provides is the 
	<classname>SimulationThread</classname> which runs
	<classname>SimulationTask</classname>s. It is special in
	that it executes all its tasks as fast as possible
	( thus without periodic sleeps ) and adjusting the
	system's clock between each <emphasis>step()</emphasis>.
	The latter allows correct timing measurement in the
	tasks running in a SimulationThread. The SimulationThread
	runs by default not-realtime, but this can be changed by
	calling the <function>SimulationThread::Instance()->makeHardRealtime()</function>
	function.
      </para>
      <para>
	The SimulationThread is started likewise the PriorityThread
	above (but without the template parameter). Its priority and
	periodicity can be changed with the configuration tool, or
	before its started.
      </para>
	<programlisting><![CDATA[
#include "corelib/SimulationTask.hpp"

using namespace ORO_CoreLib;

ORO_main( int argc, char** argv)
{
  // Define your tasks

  // ...

  // Manually start the simulation thread
  // 0.001 : The (virtual) period :  no task can run 'faster' than this.
  SimulationThread::Instance()->periodSet( 0.001 );
  SimulationThread::Instance()->start();

  // Optional, might hang your program :
  SimulationThread::Instance()->makeHardRealtime();

  // fast_sim_task will measure 0.001s elapses between each step(),
  // slow_sim_task will measure 0.01s elapses in time between each step()
  SimulationTask fast_sim_task(0.001, &vel_loop);
  SimulationTask slow_sim_task(0.01, &pos_loop);

  // All is transparant from here on.
  fast_sim_task->start();
  slow_sim_task->start();

  // ...

  fast_sim_task->stop();
  slow_sim_task->stop();

  return 0;
}
]]>
	</programlisting>
      <warning>
	<para>
	  If other threads are running in the same program executable,
	  they will also 'notice' the fast system time changes if the SimulationThread
	  is started. It is thus advisable not to mix SimulationThreads with
	  other threads. Also, any thread with lower priority than the 
	  SimulationThread will never run.
	</para>
      </warning>
    </sect2>
    <sect2>
      <title>Non Periodic Tasks</title>
      <para>
	Non periodic ( blocking ) tasks can only run in <emphasis>non periodic</emphasis> threads, or 
	( non blocking ) <emphasis>after</emphasis> all periodic tasks of a certain periodic thread. The
	latter to avoid excessive jitter in periodic task execution.
      </para>
      <para>
	If you want to create a task which reads file-IO, or displays
	information or does any other possibly blocking operation, 
	the <classname>ORO_OS::SingleThread</classname> implementation must be
	used. When it is <function>start()</function>'ed, its step() method will be called
	exactly once and then it will stop, after which it can be started again.
	The user needs to implement a <classname>ORO_OS::RunnableInterface</classname> which can be used
	by the thread for executing the user's functions.
	This thread is also introduced in the Orocos Operating System
	Abstraction Manual. 
      </para>
      <para>
	An alternative way to use non periodic tasks is to use
	the <classname>ORO_CoreLib::TaskEventDriven</classname>,
	which can be bound to an <classname>Event</classname> (see <xref linkend="corelib-events" /> )
	and each time the Event is fired up, the step() method will be invoked
	asynchronously in a given thread.
	This will happen from the moment the task's start method is called
	until the stop method is called. The following example shows
	how such a task can be run asynchronously.
	<programlisting>
  #include &lt;corelib/TaskEventDriven.hpp>

  //...
  Event&lt;void(void)> task_event;
  TaskEventDriven task( &amp;task_event, ZeroTimeThread::Instance(), &amp;run_obj);

  task_event.fire(); // nothing happens

  task.start();      // initialize()s task
  task_event.fire(); // task's step() will be executed once in ZeroTimeThread

  task.stop();       // finalize()s task
	</programlisting>
      </para>
    </sect2>
    <sect2 id="core-priority-inversions">
      <title>Priority Inversions</title>
      <para>
	A Priority inversion is the term used to indicate a scheduling situation
	in which a high priority thread is blocked on a resource which is held
	by a low priority thread, while a medium priority thread is running,
	preventing the low priority thread to free the resource for the high
	priority thread. 
      </para>
      <para>
	The result is an inverted priority because a medium priority thread
	is running while the high priority thread should be runnen, hence, 
	the medium priority thread has, in practice, a higher priority than
	the high priority thread.
      </para>
      <para>
	There are roughly said two solution to this problem. 1. Do 
	not block on resources from high priority threads. 2. Use priority
	inheritance, where a thread gets the priority of the highest priority
	thread being blocked on a resource it holds. Once it releases the
	resource, its priority goes back to normal and the high priority thread
	can resume.
      </para>
      <para>
	In essence, Orocos does not know of priority inversions and does not
	know if the underlying Operating System properly solves this common
	situation. Furthermore, it can be prooven that there are situations 
	where priority inheritance does not work.
	Therefore, we try to provide as much as possible lock-free
	implementations of inter-thread messaging. <xref linkend="core-priority-inversion-table"/>
	lists the know uses of Orocos which <emphasis>might</emphasis> lead
	to priority inversion. 
      </para>
      <table id="core-priority-inversion-table">
	<title>Classes Possibly Subject to Priority Inversion</title>
	<tgroup cols="2">
	  <thead>
	    <row>
	      <entry>Class/method</entry>
	      <entry>Rationale</entry>
	    </row>
	  </thead>
	  <tbody>
	    <row>
	      <entry>BufferCircular, BufferSimple, DataObjectLocked</entry>
	      <entry>
		<para>Uses Mutex for serialising concurrent access. Alternative
		Lock-free implementations are possible.</para>
	      </entry>
	    </row>
	    <row>
	      <entry>Event::fire()</entry>
	      <entry>
		<para>Uses Mutex for serialising concurrent access.
		No Alternative implementation is possible, callback execution
		<emphasis>must</emphasis> be serialised.</para>
	      </entry>
	    </row>
	    <row>
	      <entry>PeriodicTask::start(), PeriodicTask::stop()</entry>
	      <entry>
		<para>( Applies to PriorityTask, TaskNonRealtime, TaskPreemptible and
		TaskNonPreemptible).
		Uses Mutex for serialising concurrent access.
		Alternative implementation might be possible in certain
		cases.</para>
	      </entry>
	    </row>
	    <row>
	      <entry>Logger</entry>
	      <entry>
		<para>Uses Mutex for serialising concurrent access.
		  No Alternative implementation is possible, IO
		  <emphasis>must</emphasis> be serialised.</para>
	      </entry>
	    </row>
	  </tbody>
	</tgroup>
      </table>
      <para><xref linkend="core-lock-free-table"/> shows communication infrastructure
	in Orocos which is especially designed to be lock-free and which is thus 
	not subject to priority inversions. It is our aim to shrink the former
	table and grow the latter in Orocos' development lifetime.</para>
      <table id="core-lock-free-table">
	<title>Classes Not Subject to Priority Inversion</title>
	<tgroup cols="2">
	  <thead>
	    <row>
	      <entry>Class/method</entry>
	      <entry>Rationale</entry>
	    </row>
	  </thead>
	  <tbody>
	    <row>
	      <entry>DataObjectLockFree</entry>
	      <entry>
		<para>Uses a single writer, multiple reader Lock-free implementation.
		  A read only returns the last written value.
		  Used by the ControlKernel application to communicate data between
		  Components.</para>
	      </entry>
	    </row>
	    <row>
	      <entry>AtomicQueue</entry>
	      <entry>
		<para>Uses Compare And Swap (CAS) to store object pointers
		in an atomic queue. Used by the Processor class to queue incomming Commands.</para>
	      </entry>
	    </row>
	    <row>
	      <entry>BufferLockFree</entry>
	      <entry>
		<para>Uses a many writers, multiple readers Lock-free CAS implementation.
		  A read returns the oldest written value in a FIFO way.
		</para>
	      </entry>
	    </row>
	  </tbody>
	</tgroup>
      </table>
    </sect2>
  </sect1>
  <sect1 id="corelib-events">
    <title>Events</title>
    <para>
      An Event is an object to which one can connect callback functions. When
      the Event is raised, the connected functions are called one
      after the other. An Event can carry data and deliver it to the
      function's arguments. Orocos allows two possibilities of
      calling the function : synchronous and asynchronous. The former
      means that when the raise method is called, all synchronous
      handlers are called in the same thread. The latter means that
      the data is stored and the callback function is called in another
      thread. The thread which will execute the deferred callback
      is chosen at connection time.
    </para>
    <para>
      The Orocos Event system has been adapted since version 0.18 to 
      use the <ulink url="http://www.boost.org/">boost::signals</ulink> library.
      An Orocos <classname>Event</classname> is derived from the
      <classname>boost::signal</classname> class. 
      A <ulink url="http://www.boost.org/doc/html/signals.html">tutorial</ulink>
      is located on the boost webpage.
    </para>
    <para>
      The Orocos Event extends the boost signal with asynchronous event handling. 
      Any kind of function can be connected to the event as long as it has the
      same signature as the Event. The raise method of an Orocos Event is
      called <methodname>fire()</methodname>.
    </para>
    <example id="core-event-example">
      <title>Using Events</title>
      <para>
	This example shows how a synchronous and asynchronous handler
	are connected to an Event.
      </para>
      <programlisting>
	    <![CDATA[
#include <corelib/Event.hpp>

using boost::bind;

class SafetyStopRobot
{
public:
    void handle() {
        // Synchronous Handler code
    std::cout << " Putting the robot in a safe state fast !" << std::endl;
    }
};

Class NotifyUser
{
public:
    void complete() {
	    //Asynchronous Completer code
	    std::cout << "The program stopped the robot !"<<std::endl;
    }
};

...
SafetyStopRobot safety;
NotifyUser      notify;

// The <..> means the callback functions must be of type "void foo(void)"
Event<void(void)> emergencyStop;
Handle emergencyHandle;

// boost::bind is a way to connect the method of an object instance to
// an event.
std::cout << "Register apropriate handlers to the Emergency Stop Event\n";
emergencyHandle = 
   emergencyStop.connect( bind( &SafetyStopRobot::handle, &safety),
	                  bind( &NotifyUser::complete, &notify) );

std::cout << "Fire the event\n";
emergencyStop.fire();

// Disconnecting the callbacks...
emergencyHandle.disconnect();

// Add only synchronous callback :
emergencyHandle = 
   emergencyStop.connect( bind( &SafetyStopRobot::handle, &safety) );

std::cout << "Doing a quiet safety stop..."<<std::endl;
emergencyStop.fire(); // User not notified

...
]]>
      </programlisting>

      <screen>
	  Register apropriate handlers to the Emergency Stop Event
	  Fire the event
	   Putting the robot in a safe state fast !
	  The program stopped the robot !
	  Doing a quiet safety stop...
	   Putting the robot in a safe state fast !
      </screen>
      <para>
	If you want to find out how boost::bind works, see the Boost
	<ulink url="http://www.boost.org/libs/bind/bind.html">bind manual</ulink>.
	You must use bind if you want to call C++ class member functions to 
	'bind' the member function to an object :
	<programlisting>
  ClassName object;
  boost::bind( &amp;ClassName::FunctionName, &amp;object)	</programlisting>
	Where ClassName::FunctionName must have the same signature as the Event.
	When the Event is <function>fire( args )</function>'d,
	<programlisting>
  object->FunctionName( args )</programlisting>
	is executed by the Event.
      </para>
      <para>When you want to call free ( C ) functions, you do not need bind :
	<programlisting>
  Event&lt;void(void)> event;
  void foo() { ... }
  event.connect( &amp;foo );</programlisting>
      </para>
    </example>
    <para>
      Whether your <function>handle()</function> and <function>complete()</function>
      methods contain deterministic code or not is up to you. It depends on the choice of the
      Event type and in which thread it is executed. A good rule of thumb is to make
      all Synchronous handling/completing deterministic time and do all the rest in 
      the Asynchronous part, which will be executed by the
      another thread.
    </para>
    <para>
      You must choose the type of <classname>Event</classname> upon
      construction. This can no longer be changed once the
      <classname>Event</classname> is created. The type is the
      same for the synchronous and asynchronous methods. If the type changes,
      the fire() method must given other arguments. For example :
      <example>
	<title>Event Types</title>
	<programlisting>
<![CDATA[
  Event<void(void)> e_1;
  e_1.fire();

  Event<void(int)>  e_2;
  e_2.fire( 3 );

  Event<void(double,double,double)>  positionEvent;
  positionEvent.fire( x, y, z);
]]>
	</programlisting>
      </example>
      The return type for synchronous events can be used analogous to
      the boost::signals library. For asynchronous callbacks, the return
      value is the default constructor. There is currently no way
      to retrieve the real return value of an asynchronous callback.
    </para>
    <sect2>
      <title>Choosing the Asynchronous Thread</title>
      <para>
	The Event implementation provides one thread for
	asynchronous execution. The Orocos Tasks package provides
	four additional threads for executing the asynchronous
	callbacks.
      </para>
      <note>
	<para>
	  For brevity, we will not use boost::bind in the following
	  examples and only use 'free' ( <emphasis>C</emphasis> ) functions as callbacks.
	  Asynchronous callbacks are bound in the same way as synchronous
	  callbacks ( <xref linkend="core-event-example"/> ).
	</para>
      </note>
      <para>
	In the example above, there was aparantly no thread choosen.
	The default thread which executes asynchronous callbacks
	is called the Completion Processor. This is a non realtime
	thread, which means that the reaction time is not bounded.
	If you want to execute the callback in another thread,
	an additional argument can be given in the
	<methodname>connect</methodname> method :
	<programlisting>
  event.connect(&amp;syn_func, &amp; asyn_func, ZeroLatencyThread::Instance() );
	</programlisting>
	The above lists how the ZeroLatencyThread will execute the
	asyn_func if event is fired(). It will do this after it has processed
	all its tasks. The other Orocos threads can do this likewise :
	<programlisting>
  event.connect(&amp;syn_func, &amp; asyn_func, ZeroTimeThread::Instance() );
  event.connect(&amp;syn_func, &amp; asyn_func, NonRealTimeThread::Instance() );
  event.connect(&amp;syn_func, &amp; asyn_func, CompletionProcessor::Instance() ); <emphasis>// Default</emphasis>
  event.connect(&amp;syn_func, &amp; asyn_func, PriorityThread&lt;N&gt;::Instance() );
	</programlisting>
	If you would write above listings in a real program, on <function>
	  event.fire()</function>, the syn_func will be called directly
	five times. The asyn_func will be called in each thread once, possibly
	preempting itself.
      </para>
      <para>
	It is also possible to only have the asyn_func called. In this
	case the synopsis is :
	<programlisting>
  event.connect( &amp; asyn_func, ZeroLatencyThread::Instance() );
	</programlisting>
	to distinguish from a synchronous callback connection. In this case
	there is no default, so if you wish to use the CompletionProcessor,
	you must specify it explicitly.
	<programlisting>
  event.connect( &amp; asyn_func, CompletionProcessor::Instance() );
	</programlisting>
      </para>
      <para>
	For convenience, the Orocos Task threads can also be choosen in another way
	by specifying the Task :
	<programlisting>
  TaskNonPreemptible my_task;
  event.connect(&amp;syn_func, &amp; asyn_func, &amp;my_task );
	</programlisting>
	or even :
	<programlisting>
  RunnableInterface* my_function;
  // put my_function in a task;
  event.connect(&amp;syn_func, &amp; asyn_func, my_function->getTask() );
	</programlisting>
	The above says that the asyn_func function should be executed
	after the my_function's task execution period.
	This is a very powerfull way of synchronising function calls
	in different threads. One should be aware that a Task is
	not always executed with every period of the Thread, meaning
	that the asyn_func could be called before the task is run,
	or even multiple times in between a task run.
      </para>
      <note>
	<para>Asynchronous event handlers can have no more than
	6 arguments in the current implementation, but more
	can be easily added.</para>
      </note>
    </sect2>
    <sect2>
      <title>Event Overrun Policy</title>
      <para>
	An Event can only be fire()'d by one thread at the same time.
	The synchronous handlers will always be executed
	as much times as the event is fire()'d. This is not the case
	for asynchronous handlers. If an Event is fire()'d multiple
	times before the completion thread executes, the asynchronous
	handler will be called only once in the completion thread's execution
	step.
      </para>
      <para>
	The question that rises is with which arguments this handler
	is called. The user can choose between the first (default) and
	the last. The first is choosen as default because this causes the least
	overhead in execution time. To choose which policy is used,
	an optional parameter can be given during connect :
      </para>
      <programlisting>
  event.connect( &amp; asyn_func, mytask, Event::OnlyLast );
  event.connect( &amp; asyn_func, mytask, Event::OnlyFirst ); // default
  event.connect( &amp; asyn_func, mytask ); // same as previous line</programlisting>
    </sect2>
    <sect2>
      <title>The Completion Processor</title>
      <para>
	The Completion Processor is implemented using the
	<classname>Singleton</classname> design pattern, like the
	periodic task threads. It is the lowest priority, not realtime
	thread in the &orocos; framework. It will execute all
	asynchronous event callbacks that have to be completed when no other work has to
	be done. The only constraint it imposes is that all functions it
	executes must require finite time to complete (it cannot
	detect timeouts). You can get its thread pointer like this :
	<programlisting>
  #include &lt;corelib/CompletionProcessor.hpp>

  CompletionProcessor::Instance()-> ... 
	</programlisting>
      </para>
    </sect2>
  </sect1>
  <sect1>
    <title>Time Measurement and Conversion</title>
    <sect2>
      <title>The TimeService</title>
      <para>
	The <classname>TimeService</classname> is implemented using the
	<classname>Singleton</classname> design pattern.
	You can query it for the current (virtual) time in clock ticks or in seconds.
	The idea here is that it is responsible for synchronising with other (distributed)
	cores, for doing, for example compliant motion with two robots. This functionality
	is not yet implemented though.
      </para>
      <para>
	When the SimulationThread is used and started, it will change the TimeService's
	clock with each period ( to simulate time progress).
	Also other threads (!) In the system will notice this change, but
	time is guaranteed to increase monotonously.
      </para>
    </sect2>
    <sect2>
      <title>Usage Example</title>
      <para>
	Also take a look at the interface documentation.
	<programlisting>
  #include &lt;corelib/TimeService.hpp>
  #include &lt;corelib/Time.hpp>

  TimeService::ticks timestamp = TimeService::Instance()->ticksGet();
  //...

  Seconds elapsed = TimeService::Instance()->secondsSince( timestamp );
	</programlisting>
      </para>
    </sect2>
  </sect1>
  <sect1>
    <title>Properties</title>
    <sect2>
      <title>Introduction</title>
      <para>
	Properties are well known in object oriented programming languages. 
	They are used to store primitive data (float, strings,...) in
	a 'PropertyBag', which can be changed by the user and has immediate
	effect on the behaviour of the program. Changing parameters of an
	algorithm is a good example where properties can be used. Each parameter
	has a value, a name and a description. The user can ask any PropertyBag
	for its contents and change the values as they see fit. Java for
	example presents a Property API. 
      </para><para>
      RTAI, LXRT and GNU/Linux have been tested succesfully
	with properties. An example of how to build a PropertyBag can be found in the
	<filename>doc/examples/properties/simple_hibernate.cpp</filename> file. 
      The Doxygen Property API should
      provide enough information for succesfully using them in your Software Component.
	<note>
	  <para>
	    Reading and writing a properties value can be done in realtime. Every other 
	    transaction, like marshalling, demarshalling or building the property
	    is not a realtime operation.
	  </para>
	  <para>
	    <example><title>Using properties</title> 
	      <programlisting>
<![CDATA[
  ...
  // a property, respresening a double of value 1.0:

  Property<double> myProp("Parameter A","A demo parameter", 1.0); // not realtime !
  myProp = 10.9; // realtime
  double a = myProp.get(); // realtime
  ...
]]>
	      </programlisting>
	    </example>
	  </para>
	</note>
      </para>
      </sect2>
      <sect2>
	<title>How should I use PropertyBag ?</title>
	<para>
        First of all, a PropertyBag is not the owner of the properties it owns,
        it merely keeps track of them, it defines a logical group of properties
        belonging together. Thus when you delete a bag, the properties in it are
        not deleted, when you clone() a bag, the properties are not cloned
        themselves. PropertyBag is thus a container of pointers to Property objects.
	</para>
    <para>
        If you want to duplicate the contents of a PropertyBag or perform recursive
        operations on a bag, you can use the helper functions we created and which
        are defined in <filename>PropertyBag.hpp</filename> (see Doxygen documentation).
        These operations are however, most likely not realtime.
    </para>
    <note><para>When you want to put a PropertyBag into another PropertyBag, you need
        to make a Property&lt;PropertyBag&gt; and insert that property into the 
        first bag.</para>
    </note>
      </sect2>
      <sect2>
	<title>Marshalling and demarshalling</title>
	<para>
        Marshalling is converting an object from machine code to a code suitable
        for transportation or storage. When an object is marshalled, a copy is made
        so that it can be restored in its original state. Demarshalling instantiates
        the object again from the marshalled copy. Common formats of marshalling are
        writing out properties or efficient binary memory copies. So properties are
        just an example of objects that can be marshalled. We wrote however specific
        marshallers for properties and property bags. These are the 
        SimpleMarshaller, XMLMarshaller, XMLRPCMarshaller, INIMarshaller and
        the CPFMarshaller (for CORBA). You will need the <ulink
        url="http://xml.apache.org/xerces-c/index.html">Xerces</ulink> library for the XML
        related marshalling.
	</para>
      <note>
	<para>
	  The marshaller uses the
	  <classname>PropertyIntrospectionInterface</classname> for
	  inspecting the type of a Property. This mechanism is called
	  double dispatching. Double dispatching is an extension of
	  the standard C++ single dispatching also known as virtual
	  functions. When a virtual function is called, the method
	  which will be invoked is dependent on the object on which it
	  gets invoked. With double dispatching, after the first
	  dispatching on the object itself, there's a second
	  dispatching done on one of the parameters of the function.
	</para>
      </note>
    </sect2>
  </sect1>
  <sect1>
    <title>The NameServer</title>
    <sect2>
      <title>Introduction</title>
      <para>
	A key element in the &orocos; framework is what we call the strong typed
	nameserver. It is a (string based) nameserver which stores name, object pairs
	of only one type of object in the local program. 
	Off course, polymorphism allows us to collect many
	derivative types into one nameserver. A nameserver allows late configuration
	of objects. All possible used objects are created first and stored in the
	nameserver. Depending of the run-time users choice (from a text file,
	console input,...), another object is retrieved from the nameserver and
	used in the program.
      </para>
    </sect2>
    <sect2>
      <title>Using the NameServer</title>
      <para>
	The header is called <filename>NameServer.hpp
	</filename> and the API is quite straight forward. The most common usage
	syntax is given below. The Doxygen documentation contains the full API.
      </para>
      <note><para>
	The most common use of nameserving is keeping track of pointers to objects.
	A NameServer almost always takes pointers to an object as arguments and 
	returns a pointer when the object is looked up again.</para>
      </note>
      <programlisting>
  // A NameServer collecting pointers to ClassA objects
  NameServer&lt; ClassA* &gt; nameserver;
  ClassA my_a;
  nameserver.registerObject( &amp;my_a, "ATeam" );
  // ...
  ClassA* an_a = nameserver.getObject( "ATeam" );
  if (an_a != 0 )
      cout &lt;&lt; "ATeam was successfully stored and retrieved !" &gt;&gt; endl;
      </programlisting>
      <para>
	A typical use of nameserving is that the nameserver is nested inside the class
	it is nameserving itself. For convenience, the constructor of that class is then
	extended to take a string as argument to indicate the (optional) desired name
	of the object. Imagine that the above ClassA had such a nested nameserver,
	in that case, it would be used as follows :
      </para>
      <programlisting>
  ClassA my_a( "The ATeam" ); // give name in constructor
  // ...
  // notice the scope ClassA:: the nameserver is nested in :
  ClassA* an_a = ClassA::nameserver.getObject( "The ATeam" );
  if (an_a != 0 )
    cout &lt;&lt; "The ATeam was successfully stored and retrieved !" &gt;&gt; endl;
      </programlisting>
      <para>
	The above technique is used in many classes inside &orocos;. Events, Devices, 
	Control Kernels and Components, ... anything you wish to configure at runtime
	can be nameserved.
      </para>
    </sect2>
  </sect1>
  <sect1>
    <title>Buffers and DataObjects</title>
    <para>
      Orocos provides some basic inter-thread buffering mechanisms in the
      <filename>corelib/buffers</filename> package. The user should be aware of
      <xref linkend="core-priority-inversions"/>
      when using the 'locked' buffers (which use a Mutex).
    </para>
    <para>
      The difference between Buffers and DataObjects is that DataObjects
      are single writer / many readers, while buffers allow many writers and readers.
      Furthermore, a DataObject always returns the last value written (and a
      write always succeeds), while a buffer
      may implement a FIFO queue to store all written values (and thus can get full).
    </para>
    <sect2 id="corelib-buffers">
      <title>Buffers</title>
      <para>
	There are two kinds of buffers presently available in Orocos. The
	<emphasis>byte</emphasis> buffers and the <emphasis>typed</emphasis>
	buffers. The former write a number of bytes and might get deprecated. The
	latter is a templated (typed) buffer which can write any kind of data
	( thus also chars ) to a threadsafe buffer.
      </para>
      <para>
	The following buffers are available :
	<itemizedlist>
	  <listitem>
	    <para><emphasis>BufferSimple, BufferCircular</emphasis> :
	      Are byte buffers, may block and are subject to priority inversions
	      ( <xref linkend="core-priority-inversions"/> ). 
	    </para>
	  </listitem>
	  <listitem>
	    <para><emphasis>BufferLockFree&lt; T > </emphasis> :
	      Is a typed buffer of type <emphasis>T</emphasis> and works as
	      a FIFO queue for storing elements of type T.
	      It is lock-free, non blocking and read and writes
	      happen in bounded time. It is not subject to  <xref linkend="core-priority-inversions"/>. 
	    </para>
	  </listitem>
	</itemizedlist>
	</para>
    </sect2>
    <sect2 id="corelib-data-objects">
      <title>DataObjects</title>
      <para>
	The data inside the DataObjects can be any valid C++ type,
	so mostly people use classes or structs, because these carry
	more semantics than just (vectors of) doubles. The default
	constructor of the data is called when the DataObject is
	constructed.  Here is an example of creating and using a
	DataObject :
	<example>
	  <title>Accessing a DataObject</title>
	  <programlisting>
	    <![CDATA[
#include <corelib/DataObjectInterfaces.hpp>

// A DataObject may also contain a class, instead of the simple
// double in this example
DataObject<double> my_Do; 
my_Do.Set( 3.14 ); 
double  contents; 
my_Do.Get( contents );   // contents == 3.14
contents  = my_Do.Get(); // equivalent
]]>
	  </programlisting>
	</example>
      </para>
      <para>
	The virtual <classname>DataObjectInterface</classname> interface
	provides the <function>Get()</function> and
	<function>Set()</function> methods that each DataObject must
	have. Semantically, <function>Set()</function> and
	<function>Get()</function> copy all contents of the
	DataObject. This interface has multiple
	implementations, depending on the specific data access locking
	needs:
	<itemizedlist>
	  <listitem>
	    <para>
	      <emphasis role="strong">DataObject</emphasis>. This is
	      the most simple DataObject implementation. The
	      <function>Get()</function> and
	      <function>Set()</function> methods directly map onto the
	      contents and can always be inlined by the compiler. It
	      offers no thread safety, but maximum efficiency for
	      copying data.
	    </para>
	  </listitem>
	  <listitem>
	    <para>
	      <emphasis role="strong">DataObjectLocked</emphasis>.
	      This is a thread safe DataObject whose
	      <function>Set()</function> and
	      <function>Get()</function> methods are guarded by a
	      single mutex. The second thread accessing this object
	      will always block, which is not always appropriate in a
	      realtime system.
	    </para>
	  </listitem>
	  <listitem>
	    <para>
	      <emphasis
		role="strong">DataObjectPrioritySet</emphasis>. This
	      is a more complex DataObject which gives always priority
	      to the thread calling <function>Set()</function>, which
	      will never block. The thread accessing
	      <function>Get()</function> will block if the
	      <function>Set()</function> thread is accessing the
	      contents. It is mainly used for sharing data between two
	      kernels, running at different priorities.
	    </para>
	    <note>
	      <para>
		This DataObject will only work if the
		<function>Set()</function> thread has the highest
		priority. When the inverse is true, data corruption
		will occur. It is obvious that this DataObject can
		only be used if both threads have static priorities
		(which is the case for all threads in the &orocos;
		framework).
	      </para>
	    </note>
	  </listitem>
	  <listitem>
	    <para>
	      <emphasis
		role="strong">DataObjectPriorityGet</emphasis>. The
	      inverse of <function>DataObjectPrioritySet</function>.
	      The thread accessing <function>Get()</function> will
	      never block.
	    </para>
	  </listitem>
	  <listitem>
	    <para>
	      <emphasis role="strong">DataObjectLockFree</emphasis>.
	      This DataObject implements a non blocking reader/writer
	      buffer which always returns the last written value to
	      the reader. If the reader is preempted with a write and
	      a read, the last read will return a newer value, while
	      the first read continues to read the uncorrupted old
	      value.  The depth of this buffer must be readers+3, for
	      the algorithm to succeed in doing every write. Apart
	      from memory consumption, it is one of the best
	      thread-safe DataObject implementations.
	    </para>
	  </listitem>
	</itemizedlist>
      </para>
    </sect2>
  </sect1>
  <sect1 id="core-logging">
    <title>Logging</title>
    <para>
      Orocos applications can have pretty complex startup and initialisation code.
      A logging framework helps to track what your program is doing. <emphasis>Logging can
      only be done in the non-realtime parts of your application, thus not in
	the Realtime Periodic Tasks !</emphasis> <xref linkend="core-reporting"/> is meant for that.  
    </para>
    <para>
      There are currently 8 loglevels :
      <table>
	<title>Logger Log Levels</title>
	<tgroup cols="3">
	  <thead>
	    <row>
	      <entry>ORO_LOGLEVEL</entry>
	      <entry>Logger::enum</entry>
	      <entry>Description</entry>
	    </row>
	  </thead>
	  <tbody>
	    <row>
	      <entry>-1</entry>
	      <entry>na</entry>
	      <entry>Completely disable logging</entry>
	    </row>
	    <row>
	      <entry>0</entry>
	      <entry>Logger::Never</entry>
	      <entry>Never log anything (to console)</entry>
	    </row>
	    <row>
	      <entry>1</entry>
	      <entry>Logger::Fatal</entry>
	      <entry>Only log Fatal errors. System will abort immediately.</entry>
	    </row>
	    <row>
	      <entry>2</entry>
	      <entry>Logger::Critical</entry>
	      <entry>Only log Critical or worse errors. System may abort shortly after.</entry>
	    </row>
	    <row>
	      <entry>3</entry>
	      <entry>Logger::Error</entry>
	      <entry>Only log Errors or worse errors. System will come to a safe stop.</entry>
	    </row>
	    <row>
	      <entry>4</entry>
	      <entry>Logger::Warning</entry>
	      <entry>[Default] Only log Warnings or worse errors. System will try to resume anyway.</entry>
	    </row>
	    <row>
	      <entry>5</entry>
	      <entry>Logger::Info</entry>
	      <entry>Only log Info or worse errors. Informative messages.</entry>
	    </row>
	    <row>
	      <entry>6</entry>
	      <entry>Logger::Debug</entry>
	      <entry>Only log Debug or worse errors. Debug messages.</entry>
	    </row>
	  </tbody>
	</tgroup>
      </table>
    </para>
    <para>
      You can change the amount of log info printed on your console by setting the environment variable
      <envar>ORO_LOGLEVEL</envar> to one of the above numbers :
      <screen>
  export ORO_LOGLEVEL=5</screen>
      The default is level 4, thus only warnings and errors are printed.
    </para>
    <para>
      The <emphasis>minimum</emphasis> log level for the <filename>orocos.log</filename>
      file is <parameter>Logger::Info</parameter>. It will get more verbose if
      you increase <envar>ORO_LOGLEVEL</envar>, but will not go below Info. 
      This file is always created if the logging infrastructure is used. You can inspect this file
      if you want to know the most usefull information of what is happening inside Orocos.
    </para>
    <para>If you want to disable logging completely, use <screen>export ORO_LOGLEVEL=-1</screen>
      before you start your program.</para>
    <para>
      For using the <classname>Logger</classname> class in your own application, consult
      the API documentation.
    </para>
    <example>
      <title>Using the Logger class</title>
      <programlisting>
  <![CDATA[
  #include <corelib/Logger.hpp>

  Logger::log() << Logger::Error << "An error Occured : " << 333 << "." << Logger::endl;
  Logger::log() << Logger::Debug << debugstring << data << Logger::endl;
  Logger::log() << " more debug info." << data << Logger::endl; ]]></programlisting>
      <para>As you can see, the Logger can be used like the standard C++ input streams.
	You may change the Log message's level using the <classname>Logger::...</classname>
	enums. The above message could result in :
      </para>
      <screen>
  0.123 [ERROR] An error Occured : 333
  0.124 [Debug] &lt;contents of debugstring and data >
  0.125 [Debug]  more debug info. &lt;...data...> </screen>
    </example>
  </sect1>
  <sect1 id="core-reporting">
    <title>Reporting</title>
      <para>
	Having a realtime process running is one thing, knowing what its internal status
	is another. The reporting classes are made in such a way that existing infrastructure can
	be extended with a Reporting Stub (<classname>ReportExporter</classname> ),
	which creates reports of the internal state
	of variables and waits for client requests to update and export the data.
	A client can then ask each existing Stub to create and
	deliver a report. A timestamp is used to tag all data. When the client
	has collected all reports, it may transform it to another format, for example,
	in a log file or a display on screen. We call these clients <classname>ReportWriter</classname>s
	since they write out the gathered reports in one or another format ( this is called 
	  <emphasis>marshalling</emphasis> ).
      </para>
      <para>
	An example of an application which uses the CoreLib reporting infrastructure
	is the Orocos Control Kernel framework.
      </para>
  </sect1>
  <sect1>
    <title>States and the StateContext</title>
    <sect2>
      <title>Introduction</title>
      <para>
	Any complex software component will sooner or later need a way to change state, depending
	on how it is used by the other components. The <classname>StateInterface</classname> 
	describes how state changes are handled. When the current state is left, its
	<function>onExit()</function> method is called. Next, the <function>onEntry()</function>
	of the new state is called and right after that its <function>handle()</function> is
	called. Each time the current state is again requested, the <function>handle()</function>
	is called again (instead of onExit() and onEntry()).
      </para>
      <para>
	So the <classname>StateInterface</classname> determines what has to be done, but 
	the decision to change state is made in the <classname>StateContext</classname>. The 
	StateContext keeps track of the current state and all valid state transitions.
	One has to 'program' the StateContext so that it knows which transitions can be made
	under which conditions. 
      </para>
    </sect2>
    <sect2>
      <title>The ConditionInterface</title>
      <para>
	The ConditionInterface is very basic :
	<programlisting>
  <![CDATA[
  class ConditionInterface
  {
  virtual bool evaluate() = 0;

  virtual void reset() {}
  };
  ]]>
	</programlisting>

	Conditions are classes that evaluate an expression and return the result. This expression
	must be defined by the user. Some examples are in the source tree, like <classname>
	  ConditionOnce</classname> (returns only true when it is the first time evaluated), 
	<classname>CondionTrue</classname> (always returns true), etc. The StateContext must have for
	each state transition a Condition object which it will <function>evaluate()</function>
	to determine if the transition is allowed. All condition objects are reset() when the
	state is entered. The Condition implementations can optionally provide a reset() method.
	All Conditions are reset() just before the new state is entered (onEntry).
      </para>
    </sect2>
    <sect2>
      <title>Programming and Requesting State Transitions</title>
      <para>
	Now how does it all work together? First, a StateContext object is created and
	all its possible States. 
	<programlisting>
  <![CDATA[
  StateInit startState;
  StateFini endState;
  StateA aState;
  StateB bState;
  StateError errState;

  ConditionTrue cTrue;
  ConditionOnce cOnce;

  StateContext context;

  ]]>
	</programlisting>
	Next, we will tell the <varname>context</varname> object which is the initial state which
	state transitions are allowed :
	<programlisting>
	  <![CDATA[
	  context.initState(&startState, &endState);

	  context.transitionSet(&startState, &aState, &cOnce);
	  context.transitionSet(&aState, &bState, &cTrue);
	  context.transitionSet(&aState, &errState, &cTrue);
	  context.transitionSet(&bState, &aState, &cTrue);
	  context.transitionSet(&bState, &errState, &cTrue);

	  ]]>
	</programlisting>
	As you can see, you can only go once from the startState to the aState, then you can
	always switch from aState to bState and back. All states are allowed to go to the 
	errorstate, but in this example, it will be impossible to leave the errorstate.</para>
      <para>
	The StateContext needs activation before it may be used :
	<programlisting>
  <![CDATA[
  ...
  context.activate();            // brings us in the startState
  context.requestState(&bState); // will return false !
  context.requestState(&aState); // ok, returns true.
  context.requestState(&bState); // ok, returns true.
  context.requestState(&errState); // returns true, but we are trapped in it.

  // we are now in the errState, recover
  context.requestFinalState();   // succeeds always !
  context.requestInitialState(); // ok from Final or Initial state
 
  // start over
  ...
   ]]> </programlisting>
	When the StateContext is in the Final State, it can be deactivated, upon which the
	Final State is left.
	<programlisting>
  context.requestFinalState();
  context.deactivate();        // context.currentState() == 0
	</programlisting>
      </para>
    </sect2>
    <sect2>
      <title>Practical use of the StateContext</title>
      <para>
	The StateContext has a method <function>requestNextState()</function> which
	tries to make the first valid transition from the current state to the
	another state it encounters. To make this workable, transitions can be
	given an optional parameter which denotes the priority. It defaults to
	zero. A high number denotes a high priority, a low number denotes a 
	low priority.
      </para>
      <para>
	Writing States and StateContexts in this way is cumbersome. The Orocos Framework has
	therefore developped a Program and State
	<ulink url="orocos-program-parser.html"> Parser</ulink> and a Program and State
	<ulink url="orocos-program-processor.html">Processor</ulink> which allow
	to define states and transitions in a scripting language.
      </para>
    </sect2>
  </sect1>
  <sect1>
    <title>Fifos</title>
    <sect2>
      <title>A warning</title>
      <warning>
	<para>
	  The fifos implementation is slightly outdated and unmaintained in the latest releases.
	  You might expect problems when trying to use them. In the past they were used to
	  communicate from kernel space to userspace programs, but since the Orocos Framework is now
	  completely situated in userspace, this communication has become obsolete.
	  To implement your own kernelspace/userspace communication, use the functions of your OS.</para>
	<para>
	  For RTAI/LXRT, also read <ulink url="http://people.mech.kuleuven.ac.be/~psoetens/lxrt/portingtolxrt.html">
	  the LXRT howto</ulink>.
	</para>
      </warning>
    </sect2>
    <sect2>
      <title>Using fifos</title>
      <para>
	Fifos are used to send data from one address space to another. For example
	from realtime to userspace or vice versa. We have four kind of fifos :
      <itemizedlist>
	<listitem><para>FifoRTIn : Used to read data in realtime from a realtime fifo</para></listitem>
	<listitem><para>FifoRTOut: Used to write data in realtime to a realtime fifo</para></listitem>
	<listitem><para>FifoUSIn : Used to read data in userspace from a realtime fifo</para></listitem>
	<listitem><para>FifoUSOut: Used to write data in userspace to a realtime fifo</para></listitem>
      </itemizedlist>
      Furthermore, one can still use the FifoRTIn/Out in userspace simulations.
      They will act as if they get their data from real fifos. The API documentation should
      be clear about how to use them.
    </para>
    <para>
      Components requireing data communition will indicate this with a <classname> WriteInterface
      </classname>,<classname>ReadInterface</classname> or <classname>ObservableReadInterface
      </classname> in their constructors argument list.
      All fifos implement one of these interfaces.
    </para>
    <note>
      <para>
	For examining which data would be sent through a fifo, one can always temporarily
	use a <classname>WriteCout</classname> object instead of a fifo, which will print the data
	to the screen instead of delivering it.
      </para>
    </note>
    </sect2>
  </sect1>
</article>
