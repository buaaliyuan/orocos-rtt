<?xml version='1.0'?>

<!DOCTYPE article PUBLIC "-//OASIS//DTD DocBook XML V4.1.2//EN"
"/usr/share/sgml/docbook/dtd/xml/4.1.2/docbookx.dtd"
[
<!ENTITY orocos      "<acronym>Orocos</acronym>">
<!ENTITY rtai        "<acronym>RTAI</acronym>">
<!ENTITY rtos        "<acronym>RTOS</acronym>">
]
>

<article>
  <articleinfo>
    <title>The Orocos Core Library Manual</title>
    <authorgroup>
      <author>
	<firstname>Peter</firstname>
	<surname>Soetens</surname>
	<affiliation>
	  <orgname>K.U.Leuven</orgname>
	  <address><country>Belgium</country></address>
	</affiliation>
      </author>

      <author>
	<firstname>Herman</firstname>
	<surname>Bruyninckx</surname>
	<affiliation>
	  <orgname>K.U.Leuven</orgname>
	  <address><country>Belgium</country></address>
	</affiliation>
      </author>
      
      <author>
	<firstname>Panagiotis</firstname>
	<surname>Issaris</surname>
	<affiliation>
	  <orgname>K.U.Leuven</orgname>
	  <address><country>Belgium</country></address>
	</affiliation>
      </author>
    </authorgroup>
    <copyright>
      <year>2002-2004</year>
      <holder>Peter Soetens, Herman Bruyninckx</holder>
    </copyright>

    <abstract>
      <para>
	This document explains the design and implementation of the
	<emphasis>Core</emphasis> component of &orocos;, the <emphasis>Open
RObot COntrol Software</emphasis> project. The Core provides
infrastructural support for the functional and application components
of the &orocos; framework. An overview of that &orocos; framework
(including installation) is
given in the general &orocos; overview document.
      </para>
    </abstract>

    <revhistory>
      <revision>
	<revnumber>0.01</revnumber>
	<date>22 Aug 2002</date>
	<authorinitials>hb</authorinitials>
	<revremark>Initial version</revremark>
      </revision>
      <revision>
	<revnumber>0.9</revnumber>
	<date>11 Nov 2002</date>
	<authorinitials>ps</authorinitials>
	<revremark>lots of updates</revremark>
      </revision>
      <revision>
	<revnumber>0.11</revnumber>
	<date>29 Oct 2003</date>
	<authorinitials>ps</authorinitials>
	<revremark>Stripped Devices and OS parts</revremark>
      </revision>
      <revision>
	<revnumber>0.12</revnumber>
	<date>2 Apr 2004</date>
	<authorinitials>ps</authorinitials>
	<revremark>StateContext updates</revremark>
      </revision>
      <revision>
	<revnumber>0.13</revnumber>
	<date>18 May 2004</date>
	<authorinitials>ps</authorinitials>
	<revremark>Change in the StateContext interface</revremark>
      </revision>
      <revision>
	<revnumber>0.14</revnumber>
	<date>2 June 2004</date>
	<authorinitials>ps</authorinitials>
	<revremark>Clarified some parts based on feedback</revremark>
      </revision>
    </revhistory>

    <legalnotice>
      <para>
	Permission is granted to copy, distribute and/or modify this document
	under the terms of the GNU Free Documentation License, Version 1.1 or
	any later version published by the Free Software Foundation, with no
	Invariant Sections, with no Front-Cover Texts, and with no Back-Cover
	Texts. A copy of this license can be found at
	<ulink
	  url="http://www.fsf.org/copyleft/fdl.html">http://www.fsf.org/copyleft/fdl.html</ulink>.
      </para>
    </legalnotice>

  </articleinfo>

  <sect1>
    <title>Introduction</title>
    <para>
      This section describes the semantics of the services
      available in the &orocos; CoreLib Package.
    </para>
    <para>
	The Core makes an abstraction of the operating system on which it runs.
	It provides C++ interfaces to only the <emphasis>minimal
	  set</emphasis> of operating system
	primitives that it needs: mutexes, condition variables and tasks.
	This is in accordance with the general developers requirements of the
      project: a minimalistic approach is much easier to scale, to maintain,
      and to port. The OS abstraction is refered to as the <emphasis> 
	OS Interfaces (OSI) </emphasis> and sometimes in older documentation
      as <emphasis>Framework OS Interfaces (FOSI)</emphasis>. Both denote
      the same thing.
	The abstraction also allows &orocos; users to build their software 
	on all supported systems with only
	a recompilation step. But the Core goes further than restricting
	the abstracted OS primitives: it also imposes a hard realtime
	<emphasis>architecture</emphasis>. This architecture is explained and
	motivated in a later Section.
      <emphasis>
	The goal of this fixed architecture is to keep 
	applications deterministic, by avoiding the classical pitfalls of
	letting application programmers freely choose the priorities of their
	tasks, and their communication primitives. Practice has indeed showed
	that most programmers do not succeed in strictly decoupling the
	functional and algorithmic parts of their code from the OS-specific
	primitives used to execute them.</emphasis>
      </para>
      <para>
	Of course, the realtime performance depends not only on
	  the underlying operating system 
	  <emphasis>but also on the hardware.</emphasis> The &orocos; CoreLib
	Package also provides an abstraction of the hardware, again in order
	to facilitate maintenance and porting. This abstraction is referred to
      as <emphasis>Device Interfaces (DI)</emphasis> or in older documentation
      as the <emphasis>Framework Device Interfaces (FDI)</emphasis>. Both
      denote the same thing.
      </para>
      <para>
	The abstractions cause (almost) no execution overhead, because the wrapping
	is solved at compile or configuration time, i.e., before the hard
	realtime tasks are running.
      </para>
  </sect1>
  <sect1>
    <title>The Orocos Thread Philosophy</title>
    <sect2>
      <title>Introduction : Task versus Thread</title>
      <para>
	Threads are the major cause of headaches in multithreaded
	systems programmers heads. Synchronisation, data protection,
	priority tweaking and resource locking must all be done very
	carefully and mostly lead to suboptimal solutions. Even more,
	the predictability of the system highly decreases with the
	introduction of more threads or interactions between threads.
      </para>
      <para>
	A high priority thread and a low priority thread are enough
	for basic control applications. The high priority thread is
	used for all tasks that need to be executed atomically. No
	action in this thread will ever be pre-empted. The low
	priority realtime thread is used for all tasks which may be
	interrupted but still have hard deadlines. It can always be
	preempted by the high priority thread. There is also a non
	realtime thread which gives no deadline guarantees. When more
	realtime threads are introduced, only the highest priority
	thread can do non-preemptive execution, and all the others
	have only deadline guarantees. When the second group gets
	larger, it gets harder for the OS to guarantee these
	deadlines, and soon, the lower priority realtime threads are
	failing. Technically, this only happens if the CPU is
	underspecified for the task, but in reality, the scheduler
	failes earlier because of non optimal scheduling. Hence users
	should only add additional realtime threads where application
	complexity demands it.
      </para>
    </sect2>
    <sect2>
      <title>Adding Additional Threads</title>
      <para>
	For users needing to solve more complex control problems, the
	PriorityThread and PriorityTask are provided with which you
	can create an arbitrary number of threads with no more than
	one thread per priority level. It needs a bit more setup than
	the standard Orocos threads, since you still have to set the
	priority and start the thread. An example is given below. 
	A PriorityThread is not automatically started like the ZeroTimeThread,
	ZeroLatencyThread and NonRealTimeThread. It must be done by the
	user. Furthermore, The PriorityThread is the general case of the
	above three cases, since its priority can match their priorities
	as given in the configuration tool.
      </para>
    </sect2>
    <sect2>
      <title>Creating Tasks</title>
      <para></para>
      <para>
	If you want to execute functionality in one of these threads, you need to 
	create a Task of a certain type, depending on the thread type. The table
	below summarises which Task type there is per thread.
	<table>
	  <title>Thread and Task summary</title>
	  <!-- one of (graphic mediaobject tgroup) -->
	  <tgroup cols="2">
	    <thead>
	      <row>
		<!-- one of (entrytbl entry) -->
		<entry>Thread</entry>
		<entry>Task</entry>
	      </row>
	    </thead>
	    <tbody>
	      <row>
		<entry>ZeroTimeThread</entry>
		<entry>TaskNonPreemptable</entry>
		<!-- one of (entrytbl entry) -->
	      </row>
	      <row>
		<!-- one of (entrytbl entry) -->
		<entry>ZeroLatencyThread</entry>
		<entry>TaskPreemptable</entry>
	      </row>
	      <row>
		<!-- one of (entrytbl entry) -->
		<entry>NonRealTimeThread</entry>
		<entry>TaskNonRealTime</entry>
	      </row>
	      <row>
		<!-- one of (entrytbl entry) -->
		<entry>PriorityThread&lt; N &gt;</entry>
		<entry>PriorityTask&lt; N &gt;</entry>
	      </row>
	    </tbody>
	  </tgroup>
	</table>
      </para>
      <example>
	<title>Example Task Creation</title>
	<para>
	  This example shows how a task can be created. When it
	  is started it will add itself to the correct thread.
	</para>
	<programlisting><![CDATA[
#include "corelib/TaskNonPreemptible.hpp"
#include "corelib/TaskPreemptible.hpp"
#include "corelib/TaskNonRealTime.hpp"
#include "corelib/PriorityTask.hpp"

using namespace ORO_CoreLib;

ORO_main( int argc, const char** argv)
{
  // Define your tasks

  // ...

  // An extra thread for low priority tasks
  // 9 : The priority.
  // 0.01 : The period.
  // You have to manually start the thread.
  PriorityThread<9>::Instance()->periodSet( 0.01 );
  PriorityThread<9>::Instance()->start();
  // Optional :
  PriorityThread<9>::Instance()->makeHardRealtime();

  // These tasks are run in the Orocos Thread Model
  TaskNonPreemptible fast_task(0.001, &vel_loop);
  TaskPreemptible slow_task(0.01, &pos_loop);
  TaskNonRealTime nrt_task( 0.1, &display_server );

  // This task is run in the extra thread above
  PriorityTask<9> own_task( 0.05, &kine_loop ); // 0.05 is multiple of 0.01

  // All is transparant from here on.
  fast_task->start();
  slow_task->start();
  own_task->start();
  nrt_task->start();

  // ...

  fast_task->stop();
  slow_task->stop();
  own_task->stop();
  nrt_task->stop();

  return 0;
}
]]>
	</programlisting>
	<para>
	  The tasks in the example are all empty since no class is
	  derived from the Task and no RunnableInterface is given
	  (see next section)
	</para>
      </example>
      <para>
	The high priority thread is the
	<classname>ZeroTimeThread</classname>. It will execute all
	<classname>TaskNonPreemptable</classname> Tasks
	synchronically. You can create your own not preemtable task by
	inheriting from this class. Its name is derived from the fact
	that some tasks need to be executed in an infinite small
	amount of time to work correctly. Control loops are an example
	of this. To come as close as possible to this (impossible)
	constraint, we make sure that the task is never preempted by
	another task and thus is executed 'atomically'.
      </para>
      <para>
	The low priority tasks are executed by the
	<classname>ZeroLatencyThread</classname> class. It will
	execute all <classname>TaskPreemptable</classname> Tasks
	sequentially, when no non-preemptable tasks are executed.
	Every <classname>TaskPreemptable</classname> can be preempted
	by a <classname>TaskNonPreemptable</classname> but not by
	another <classname>TaskPreemptable</classname>. The
	ZeroLatencyThread has this name because the zero time
	constraint is dropped, but replaced by the constraint that no
	latency may occur and thus, execution is still realtime.
	Again, to satisfy this constraint, only deterministic time
	operations may be done in this thread.
      </para>
      <para>
	For not realtime executions, as there are userspace
	communication, memory allocations,... we use the
	NonRealTimeThread. Roughly put, you can do
	<emphasis>anything</emphasis> in this thread, as long as it
	takes finite time. This is the lowest priority thread in the
	system and it should never lock a resource of the realtime
	thread. Tasks being executed in the NonRealTimeThread are
	called <classname>TaskNonRealTime</classname>.
      </para>
    </sect2>
    <sect2>
      <title>Putting Functionality in a Task</title>
      <para>
	There are two ways to run functionality in a task. By :
	<itemizedlist>
	  <listitem>
	    <para>
	      Implementing the <classname>RunnableInterface</classname>  in another class
	      ( functions initialize, step and finalize ). The RunnableInterface object (i.e. run_impl) can
	      be assigned to a task using <synopsis> task.run( &amp;run_impl )</synopsis> or
	      at construction time of a Task : <synopsis> TaskNonPreemptible task( period, &amp;run_impl );</synopsis>.
	    </para>
	  </listitem>
	  <listitem>
	    <para>
	      Inheriting from a Task class and overriding the initialize, step
	      and finalize methods.
	    </para>
	  </listitem>
	</itemizedlist>
	The Task will detect if it must run an external RunnableInterface. If none
	was given, it will call its own virtual methods.
      </para>
    </sect2>
    <sect2>
      <title>Task Ordering</title>
      <para>
	Tasks are executed <emphasis>in the order as they are started</emphasis>.
	The Thread responsible
	for the Task will execute all tasks one after the other, respecting
	the periodicity of the task. This means that a Task with a lower periodicity
	of the thread (e.g. 10 times lower) will only be called a fraction of the
	time (thus every 10th period), still respecting the ordering.
      </para>
      <para>
	<figure><title>Execution sequence diagram</title>
	  <mediaobject>
	    <imageobject role="html">
	      <imagedata fileref="execution-sequence.png" format="PNG"/>
	    </imageobject>
	    <imageobject role="fo">
	      <imagedata fileref="execution-sequence.eps" format="EPS"/>
	    </imageobject>
	    <!--
	    <caption><para>
	  </para></caption>
	    -->
	  </mediaobject>
	</figure>
      </para>
    </sect2>
  </sect1>
  <sect1>
    <title>Events</title>
    <para>
      An Event is an object to which one can connect callback functions. When
      the Event is raised, the connected functions are called one
      after the other. An Event can carry data and deliver it to the
      function's arguments. Orocos allows two possibilities of
      calling the function : synchronous and asynchronous. The former
      means that when the raise method is called, all synchronous
      handlers are called in the same thread. The latter means that
      the data is stored and the callback function is called in another
      thread. The thread which will execute the deferred callback
      is chosen at connection time.
    </para>
    <para>
      The Orocos Event system has been adapted since version 0.18 to 
      use the <ulink url="http://www.boost.org/">boost::signals</ulink> library.
      An Orocos <classname>Event</classname> is derived from the
      <classname>boost::signal</classname> class. 
      A <ulink url="http://www.boost.org/doc/html/signals.html">tutorial</ulink>
      is located on the boost webpage.
    </para>
    <para>
      The Orocos Event extends the boost signal with asynchronous event handling. 
      Any kind of function can be connected to the event as long as it has the
      same signature as the Event. The raise method of an Orocos Event is
      called <methodname>fire()</methodname>.
    </para>
    <example><title>Using Events</title>
      <para>
	This example shows how a synchronous and asynchronous handler
	are connected to an Event.
      </para>
      <programlisting>
	    <![CDATA[
#include <corelib/Event.hpp>

using boost::bind;

class SafetyStopRobot
{
public:
    void handle() {
        // Synchronous Handler code
    std::cout << " Putting the robot in a safe state fast !" << std::endl;
    }
};

Class NotifyUser
{
public:
    void complete() {
	    //Asynchronous Completer code
	    std::cout << "The program stopped the robot !"<<std::endl;
    }
};

...
SafetyStopRobot safety;
NotifyUser      notify;

// The <..> means the callback functions must be of type "void foo(void)"
Event<void(void)> emergencyStop;
Handle emergencyHandle;

std::cout << "Register apropriate handlers to the Emergency Stop Event\n";
emergencyHandle = 
   emergencyStop.connect( bind( &SafetyStopRobot::handle, &safety),
	                  bind( &NotifyUser::complete, &notify) );

std::cout << "Fire the event\n";
emergencyStop.fire();

// Disconnecting the callbacks...
emergencyHandle.disconnect();

// Add only synchronous callback :
emergencyHandle = 
   emergencyStop.connect( bind( &SafetyStopRobot::handle, &safety) );

std::cout << "Doing a quiet safety stop..."<<std::endl;
emergencyStop.fire(); // User not notified

...
]]>
      </programlisting>

      <screen>
	  Register apropriate handlers to the Emergency Stop Event
	  Fire the event
	   Putting the robot in a safe state fast !
	  The program stopped the robot !
	  Doing a quiet safety stop...
	   Putting the robot in a safe state fast !
      </screen>
      <para>
	Off course, the <emphasis>Putting the robot in a safe state fast !</emphasis>
	sentence should be replaced with the actual call to stop the robot.
      </para>
      <para>
	If you want to find out how boost::bind works, see the Boost
	<ulink url="http://www.boost.org/libs/bind/bind.html">bind manual</ulink>.
      </para>
    </example>
  </para>
    <para>
      Whether your <function>handle()</function> and <function>complete()</function>
      methods contain deterministic code or not is up to you. It depends on the choice of the
      Event type and in which thread it is executed. A good rule of thumb is to make
      all Synchronous handling/completing deterministic time and do all the rest in 
      the Asynchronous part, which will be executed by the
      another thread.
    </para>
    <para>
      You must choose the type of <classname>Event</classname> upon
      construction. This can no longer be changed once the
      <classname>Event</classname> is created. The type is the
      same for the synchronous and asynchronous methods. If the type changes,
      the fire() method must given other arguments. For example :
      <example>
	<title>Event Types</title>
	<programlisting>
<![CDATA[
  Event<void(void)> e_1;
  e_1.fire();

  Event<void(int)>  e_2;
  e_2.fire( 3 );

  Event<void(double,double,double)>  positionEvent;
  positionEvent.fire( x, y, z);
]]>
	</programlisting>
      </example>
      The return type for synchronous events can be used analogous to
      the boost::signals library. For asynchronous callbacks, the return
      value is the default constructor. There is currently no way
      to retrieve the real return value of an asynchronous callback.
    </para>
    <sect2>
      <title>Choosing the Asynchronous Thread</title>
      <para>
	The Event implementation provides one thread for
	asynchronous execution. The Orocos Tasks package provides
	four additional threads for executing the asynchronous
	callbacks.
      </para>
      <para>
	In the example above, there was aparantly no thread choosen.
	The default thread which executes asynchronous callbacks
	is called the Completion Processor. This is a non realtime
	thread, which means that the reaction time is not bounded.
	If you want to execute the callback in another thread,
	an additional argument can be given in the
	<methodname>connect</methodname> method :
	<programlisting>
  event.connect(&amp;syn_func, &amp; asyn_func, ZeroLatencyThread::Instance() );
	</programlisting>
	The above lists how the ZeroLatencyThread will execute the
	asyn_func if event is fired(). It will do this after it has processed
	all its tasks. The other Orocos threads can do this likewise :
	<programlisting>
  event.connect(&amp;syn_func, &amp; asyn_func, ZeroTimeThread::Instance() );
  event.connect(&amp;syn_func, &amp; asyn_func, NonRealTimeThread::Instance() );
  event.connect(&amp;syn_func, &amp; asyn_func, CompletionProcessor::Instance() ); // Default
  event.connect(&amp;syn_func, &amp; asyn_func, PriorityThread&lt;N&gt;::Instance() );
	</programlisting>
	If you would write above listings in a real program, on <methodsynopsis>
	  event.fire()</methodsynopsis>, the syn_func will be called directly
	five times. The asyn_func will be called in each thread once, possibly
	preempting itself.
      </para>
      <para>
	It is also possible to only have the asyn_func called. In this
	case the synopsis is :
	<programlisting>
  event.connect( &amp; asyn_func, ZeroLatencyThread::Instance() );
	</programlisting>
	to distinguish from a synchronous callback connection. In this case
	there is no default, so if you wish to use the Completion Processor,
	you must specify it explicitly.
      </para>
      <para>
	For convenience, the Orocos Task threads can also be choosen in another way
	by specifying the Task :
	<programlisting>
  TaskNonPreemptible my_task;
  event.connect(&amp;syn_func, &amp; asyn_func, &amp;my_task );
	</programlisting>
	or even :
	<programlisting>
  RunnableInterface* my_function;
  // put my_function in a task;
  event.connect(&amp;syn_func, &amp; asyn_func, my_function->getTask() );
	</programlisting>
	The above says that the asyn_func function should be executed
	after the my_function's task execution period.
	This is a very powerfull way of synchronising function calls
	in different threads. One should be aware that a Task is
	not always executed with every period of the Thread, meaning
	that the asyn_func could be called before the task is run,
	or even multiple times in between a task run.
      </para>
      <note>
	<para>Asynchronous event handlers can have no more than
	6 arguments in the current implementation, but more
	can be easily added.</para>
      </note>
    </sect2>
<!--
    <sect2>
	<title>Available Event Policies</title>
	<para>
	  Our subscription based Event is just an example of the many possibilities of Events in
	  general. We provide four other Event primitives which you will need in your Event based
	  applications.
	</para>
      <sect3>
	<title>EventSimple</title>
	<para>
	  <classname>EventSimple</classname> is a simplification of the general Event. 
	  It can have exactly one Listener and one Completer, which can be set or removed.
	  You can use this Event in case you want to be sure that only one Listener and
	  one Completer are notified when this event is fire()'d.
	</para>
      </sect3>
      <sect3>
	<title>EventMultiCast</title>
	<para>
	  <classname>EventMultiCast</classname> has one Listener and many Completers.
	  When the event is fire()d and the Listener calls for complete()'ion,
	  all subscribed Completers will be notified. In this sence, not the fire
	  call is MultiCasted, but the complete call is MultiCasted to all Completers.
	</para>
      </sect3>
      <sect3>
	<title>EventBarrier</title>
	<para>
	  <classname>EventBarrier</classname> has many Listeners and one Completer.
	  When the event is fire()d and the Listener calls for complete()'ion,
	  the Completer will only be notified if all Listeners called the
	  complete() method. A new fire() method call will reset all complete() calls
	  and wait again for all Listeners to call complete() before the Completer
	  is notified.
	</para>
	<para>
	  An example is an EmergencyStop Event. Some program logic decides that the
	  EmergencyStop Event must be fired. All Listeners are called and perform
	  their emergency stop handling and call the complete() method. When
	  all Listeners called this, the Completer is called which now knows
	  that everyone stopped safely and can report this to the user or another
	  component. It is as if the Completer was on hold until all Listeners were
	  ready, hence the word barrier.
	</para>
      </sect3>
      <sect3>
	<title>EventPeriodic</title>
	<para>
	  <classname>EventPeriodic</classname> is a special case of the Event
	  subscription model. That is, the Listener-Completer mapping is N to N,
	  as with the normal Event, but the fireing of the event results in
	  periodically notifying of Listeners. For example, if the periodicity
	  is 10 to 1, each Listener will have been called exactly once after
	  the EventPeriodic was fired ten times. For each Listener, it is as 
	  if the fire calls are done with longer periods in between.
	</para>
	<para>
	  This Event is used in the &orocos; Threading classes for executing
	  tasks at a lower frequency than the thread is running.
	</para>
      </sect3>
      <sect3>
	<title>EventDivider</title>
	<para>
	  <classname>EventDivider</classname> is also a special case of the Event
	  subscription model. That is, the Listener-Completer mapping is N to N,
	  as with the normal Event, but the notifying of the Listeners of the 
	  event will only happen after X effective fire calls. It is as if
	  The Event divides the firing by factor X.
	</para>
      </sect3>
    </sect2>
-->
    <sect2>
      <title>The Completion Processor</title>
      <para>
	The Completion Processor is implemented using the
	<classname>Singleton</classname> design pattern, like the
	periodic task threads. It is the lowest priority, not realtime
	thread in the &orocos; framework. It will execute all
	callbacks that have to be completed when no other work has to
	be done. The only constraint it has is that all functions it
	executes should require finite time to complete (it cannot
	detect timeouts).
      </para>
    </sect2>
  </sect1>
  <sect1>
    <title>The HeartbeatGenerator</title>
    <sect2>
      <title>Purpose</title>
      <para>
	The <classname>HeartbeatGenerator</classname> is implemented using the
	<classname>Singleton</classname> design pattern.
	You can query it for the current (virtual) time in clock ticks or in seconds.
	The idea here is that it is responsible for synchronising with other (distributed)
	cores, for doing, for example compliant motion with two robots. This functionality
	is not yet implemented though.
      </para>
    </sect2>
  </sect1>
  <sect1>
      <title>States and the StateContext</title>
    <sect2>
      <title>Introduction</title>
      <para>
	Any complex software component will sooner or later need a way to change state, depending
	on how it is used by the other components. The <classname>StateInterface</classname> 
	describes how state changes are handled. When the current state is left, its
	<function>onExit()</function> method is called. Next, the <function>onEntry()</function>
	of the new state is called and right after that its <function>handle()</function> is
	called. Each time the current state is again requested, the <function>handle()</function>
	is called again (instead of onExit() and onEntry()).
      </para>
      <para>
	So the <classname>StateInterface</classname> determines what has to be done, but 
	the decision to change state is made in the <classname>StateContext</classname>. The 
	StateContext keeps track of the current state and all valid state transitions.
	One has to 'program' the StateContext so that it knows which transitions can be made
	under which conditions. 
      </para>
    </sect2>
     <sect2>
	<title>The ConditionInterface</title>
	<para>
	  The ConditionInterface is very basic :
	  <programlisting>
  <![CDATA[
  class ConditionInterface
  {
  virtual bool evaluate() = 0;

  virtual void reset() {}
  };
  ]]>
	  </programlisting>

	  Conditions are classes that evaluate an expression and return the result. This expression
	  must be defined by the user. Some examples are in the source tree, like <classname>
	    ConditionOnce</classname> (returns only true when it is the first time evaluated), 
	  <classname>CondionTrue</classname> (always returns true), etc. The StateContext must have for
	  each state transition a Condition object which it will <function>evaluate()</function>
	  to determine if the transition is allowed. All condition objects are reset() when the
	  state is entered. The Condition implementations can optionally provide a reset() method.
	  All Conditions are reset() just before the new state is entered (onEntry).
	</para>
      </sect2>
      <sect2>
	<title>Programming and Requesting State Transitions</title>
	<para>
	  Now how does it all work together ? First, a StateContext object is created and
	  all its possible States. 
	  <programlisting>
  <![CDATA[
  StateInit startState;
  StateFini endState;
  StateA aState;
  StateB bState;
  StateError errState;

  ConditionTrue cTrue;
  ConditionOnce cOnce;

  StateContext context;

  ]]>
	  </programlisting>
	  Next, we will tell the <varname>context</varname> object which is the initial state which
	  state transitions are allowed :
	  <programlisting>
	    <![CDATA[
	    context.initState(&startState, &endState);

	    context.transitionSet(&startState, &aState, &cOnce);
	    context.transitionSet(&aState, &bState, &cTrue);
	    context.transitionSet(&aState, &errState, &cTrue);
	    context.transitionSet(&bState, &aState, &cTrue);
	    context.transitionSet(&bState, &errState, &cTrue);

	    ]]>
	  </programlisting>
	  As you can see, you can only go once from the startState to the aState, then you can
	  always switch from aState to bState and back. All states are allowed to go to the 
	  errorstate, but in this example, it will be impossible to leave the errorstate:
	  <programlisting>
  <![CDATA[
  ...
  // we are in the startState
  context.requestState(&bState); // will return false !
  context.requestState(&aState); // ok, returns true.
  context.requestState(&bState); // ok, returns true.
  context.requestState(&errState); // returns true, but we are trapped in it.

  // we are now in the errState, recover
  context.requestFinalState();   // succeeds always !
  context.requestInitialState(); // ok from Final or Initial state
 
  // start over
  ...
   ]]>
	  </programlisting>
	</para>
      </sect2>
    <sect2>
      <title>Practical use of the StateContext</title>
      <para>
	The StateContext has a method <function>requestNextState()</function> which
	tries to make the first valid transition from the current state to the
	another state it encounters. To make this workable, transitions can be
	given an optional parameter which denotes the priority. It defaults to
	zero. A high number denotes a high priority, a low number denotes a 
	low priority.
      </para>
      <para>
	Writing States and StateContexts in this way is cumbersome. The Orocos Framework has
	therefore developped a Program and State
	<ulink url="orocos-program-parser.html"> Parser</ulink> and a Program and State
	<ulink url="orocos-program-processor.html">Processor</ulink>
	which are documented seperately.
      </para>
    </sect2>
  </sect1>
  <sect1>
    <title>Properties</title>
    <sect2>
      <title>Introduction</title>
      <para>
	Properties are well known in object oriented programming languages. 
	They are used to store primitive data (float, strings,...) in
	a 'PropertyBag', which can be changed by the user and has immediate
	effect on the behaviour of the program. Changing parameters of an
	algorithm is a good example where properties can be used. Each parameter
	has a value, a name and a description. The user can ask any PropertyBag
	for its contents and change the values as they see fit. Java for
	example presents a Property API. 
      </para><para>
      RTAI, LXRT and GNU/Linux have been tested succesfully
	with properties. An example of how to build a PropertyBag can be found in the
	<filename>doc/examples/properties/simple_hibernate.cpp</filename> file. 
      The Doxygen Property API should
      provide enough information for succesfully using them in your Software Component.
	<note>
	  <para>
	    Reading and writing a properties value can be done in realtime. Every other 
	    transaction, like marshalling, demarshalling or building the property
	    is not a realtime operation.
	  </para>
	  <para>
	    <example><title>Using properties</title> 
	      <programlisting>
<![CDATA[
  ...
  // a property, respresening a double of value 1.0:

  Property<double> myProp("Parameter A","A demo parameter", 1.0); // not realtime !
  myProp = 10.9; // realtime
  double a = myProp.get(); // realtime
  ...
]]>
	      </programlisting>
	    </example>
	  </para>
	</note>
      </para>
      </sect2>
      <sect2>
	<title>How should I use PropertyBag ?</title>
	<para>
        First of all, a PropertyBag is not the owner of the properties it owns,
        it merely keeps track of them, it defines a logical group of properties
        belonging together. Thus when you delete a bag, the properties in it are
        not deleted, when you clone() a bag, the properties are not cloned
        themselves. PropertyBag is thus a container of pointers to Property objects.
	</para>
    <para>
        If you want to duplicate the contents of a PropertyBag or perform recursive
        operations on a bag, you can use the helper functions we created and which
        are defined in <filename>PropertyBag.hpp</filename> (see Doxygen documentation).
        These operations are however, most likely not realtime.
    </para>
    <note><para>When you want to put a PropertyBag into another PropertyBag, you need
        to make a Property&lt;PropertyBag&gt; and insert that property into the 
        first bag.</para>
    </note>
      </sect2>
      <sect2>
	<title>Marshalling and demarshalling</title>
	<para>
        Marshalling is converting an object from machine code to a code suitable
        for transportation or storage. When an object is marshalled, a copy is made
        so that it can be restored in its original state. Demarshalling instantiates
        the object again from the marshalled copy. Common formats of marshalling are
        writing out properties or efficient binary memory copies. So properties are
        just an example of objects that can be marshalled. We wrote however specific
        marshallers for properties and property bags. These are the 
        SimpleMarshaller, XMLMarshaller, XMLRPCMarshaller, INIMarshaller and
        the CPFMarshaller (for CORBA). You will need the <ulink
        url="http://xml.apache.org/xerces-c/index.html">Xerces</ulink> library for the XML
        related marshalling.
	</para>
      <note>
	<para>
	  The marshaller uses the
	  <classname>PropertyIntrospectionInterface</classname> for
	  inspecting the type of a Property. This mechanism is called
	  double dispatching. Double dispatching is an extension of
	  the standard C++ single dispatching also known as virtual
	  functions. When a virtual function is called, the method
	  which will be invoked is dependent on the object on which it
	  gets invoked. With double dispatching, after the first
	  dispatching on the object itself, there's a second
	  dispatching done on one of the parameters of the function.
	</para>
      </note>
    </sect2>
  </sect1>
  <sect1>
    <title>The NameServer</title>
    <sect2>
      <title>Introduction</title>
      <para>
	A key element in the &orocos; framework is what we call the strong typed
	nameserver. It is a (string based) nameserver which stores name, object pairs
	of only one type of object in the local program. 
	Off course, polymorphism allows us to collect many
	derivative types into one nameserver. A nameserver allows late configuration
	of objects. All possible used objects are created first and stored in the
	nameserver. Depending of the run-time users choice (from a text file,
	console input,...), another object is retrieved from the nameserver and
	used in the program.
      </para>
    </sect2>
    <sect2>
      <title>Using the NameServer</title>
      <para>
	The header is called <filename>NameServer.hpp
	</filename> and the API is quite straight forward. The most common usage
	syntax is given below. The Doxygen documentation contains the full API.
      </para>
      <note><para>
	The most common use of nameserving is keeping track of pointers to objects.
	A NameServer almost always takes pointers to an object as arguments and 
	returns a pointer when the object is looked up again.</para>
      </note>
      <programlisting>
  // A NameServer collecting pointers to ClassA objects
  NameServer&lt; ClassA* &gt; nameserver;
  ClassA my_a;
  nameserver.registerObject( &amp;my_a, "ATeam" );
  // ...
  ClassA* an_a = nameserver.getObject( "ATeam" );
  if (an_a != 0 )
      cout &lt;&lt; "ATeam was successfully stored and retrieved !" &gt;&gt; endl;
      </programlisting>
      <para>
	A typical use of nameserving is that the nameserver is nested inside the class
	it is nameserving itself. For convenience, the constructor of that class is then
	extended to take a string as argument to indicate the (optional) desired name
	of the object. Imagine that the above ClassA had such a nested nameserver,
	in that case, it would be used as follows :
      </para>
      <programlisting>
  ClassA my_a( "The ATeam" ); // give name in constructor
  // ...
  // notice the scope ClassA:: the nameserver is nested in :
  ClassA* an_a = ClassA::nameserver.getObject( "The ATeam" );
  if (an_a != 0 )
    cout &lt;&lt; "The ATeam was successfully stored and retrieved !" &gt;&gt; endl;
      </programlisting>
      <para>
	The above technique is used in many classes inside &orocos;. Events, Devices, 
	Control Kernels and Components, ... anything you wish to configure at runtime
	can be nameserved.
      </para>
    </sect2>
  </sect1>
  <sect1>
    <title>Reporting</title>
    <sect2>
      <title>Introduction</title>
      <para>
	Having a realtime process running is one thing, knowing what its internal status
	is is another. Reporting is made in such a way that existing components can
	be extended with a Reporting Stub, which creates reports of the internal state
	of variables and waits for client requests to update or export the data. 
	A client can then ask each existing Stub to create and
	deliver a report. A timestamp is used to tag all data. When the client
	has collected all reports, it may transform it to another format, for example,
	in a log file or a display on screen. We call these clients often ReportWriters
	since they write out the gathered reports in one or another format.
	An example of an application is a realtime robot component
	which delivers every 10ms its position, velocity and sensor data 
	to a userspace map building application.
      </para>
    </sect2>
  </sect1>
  <sect1>
    <title>Fifos</title>
    <sect2>
      <title>A warning</title>
      <warning>
	<para>
	  The fifos implementation is slightly outdated and unmaintained in the latest releases.
	  You might expect problems when trying to use them. In the past they were used to 
	  communicate from kernel space to userspace programs, but since the Orocos Framework is now 
	  completely situated in userspace, this communication has become obsolete.
	</para>
      </warning>
    </sect2>
    <sect2>
      <title>Using fifos</title>
      <para>
	Fifos are used to send data from one address space to another. For example
	from realtime to userspace or vice versa. We have four kind of fifos :
      <itemizedlist>
	<listitem><para>FifoRTIn : Used to read data in realtime from a realtime fifo</para></listitem>
	<listitem><para>FifoRTOut: Used to write data in realtime to a realtime fifo</para></listitem>
	<listitem><para>FifoUSIn : Used to read data in userspace from a realtime fifo</para></listitem>
	<listitem><para>FifoUSOut: Used to write data in userspace to a realtime fifo</para></listitem>
      </itemizedlist>
      Furthermore, one can still use the FifoRTIn/Out in userspace simulations.
      They will act as if they get their data from real fifos. The API documentation should
      be clear about how to use them.
    </para>
    <para>
      Components requireing data communition will indicate this with a <classname> WriteInterface
      </classname>,<classname>ReadInterface</classname> or <classname>ObservableReadInterface 
      </classname> in their constructors argument list.
      All fifos implement one of these interfaces.
    </para>
    <note>
      <para>
	For examining which data would be sent through a fifo, one can always temporarily
	use a <classname>WriteCout</classname> object instead of a fifo, which will print the data
	to the screen instead of delivering it.
      </para>
    </note>
    </sect2>
  </sect1>
</article>
